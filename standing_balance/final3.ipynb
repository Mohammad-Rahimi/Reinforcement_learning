{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "### Due Date: Friday, March 20\n",
    "\n",
    "### Policy Gradient\n",
    "\n",
    "In this assignment, we will implement vanilla policy gradient algorithm (REINFORCE) covered in the lecture. You will work on i) a function approximator, ii) computing action, iii) collecting samples, iV) training the agent, V) plotting the resutls. \n",
    "\n",
    "\n",
    "***Complete the missing operations and test your implemented algorithm on the Gym environment.***\n",
    "\n",
    "***Software requirements:***\n",
    "- Python >= 3.6\n",
    "- Tensorflow version <= 1.15.3 (1.X version)\n",
    "- OpenAI Gym\n",
    "\n",
    "- Training the agent (policy) can take long time. It is recomended to start solving the problems earlier.\n",
    "\n",
    "- Save any plots you generated in this notebook. The grade will be given based on the plots you showed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the packages you installed meet the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "gym.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Tensorflow Implementation\n",
    "\n",
    "We will be implementing policy gradient algorithm using Tensorflow 1.X., which simply updates the parameters of policy from obtaining gradient estimates. The core of policy gradient is to design a function approximator, computing actions, collecting samples, and training the policy. In the below cell, you are encouraged to fill in the components that are missing. ***Your tasks*** are \n",
    "\n",
    "1. Complete the 'create_model' method to output the mean value for diagonal Guassian policy. Covariance is already defined in the model, so focus on creating neural network model.\n",
    "\n",
    "2. Complete the 'action_op' method to calculate and return the actions for diagonal Gaussian policy. The applied action should be $\\pi(s) = \\pi_{\\text{mean}}(s) + exp(logstd) * \\mathcal{N}(0,1)$\n",
    "\n",
    "***Hints***:\n",
    "- Some useful tensorflow classes and methods include: 'tf.exp', 'tf.random_normal'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***IF you are using MAC, please run below box***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# MAC user only\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import ipdb\n",
    "\n",
    "\n",
    "class PolicyOpt(object):\n",
    "\n",
    "    def __init__(self, env, linear=False, stochastic=True, hidden_size=32, nonlinearity=tf.nn.relu):\n",
    "        \"\"\"Instantiate the policy iteration class.\n",
    "\n",
    "        This initializes the policy optimization with a set of trainable \n",
    "        parameters, and creates a tensorflow session.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        env : gym.Env\n",
    "            the environment that the policy will be trained on\n",
    "        linear : bool, optional\n",
    "            specifies whether to use a linear or neural network \n",
    "            policy, defaults to False (i.e. Fully-Connected-Neural-Network)\n",
    "        stochastic : bool, optional\n",
    "            specifies whether to use a stochastic or deterministic \n",
    "            policy, defaults to True\n",
    "        hidden_size : list of int, optional\n",
    "            list of hidden layers, with each value corresponding \n",
    "            to the number of nodes in that layer \n",
    "        nonlinearity : tf.nn.*\n",
    "            activation nonlinearity\n",
    "        \"\"\"\n",
    "        \n",
    "        # clear computation graph\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # set a random seed\n",
    "        tf.set_random_seed(1234)\n",
    "        \n",
    "        # start a tensorflow session\n",
    "        self.sess = tf.Session()\n",
    "        \n",
    "        # environment to train on\n",
    "        self.env = env\n",
    "        \n",
    "        # number of elements in the action space\n",
    "        self.ac_dim = env.action_space.shape[0]\n",
    "        \n",
    "        # number of elements in the observation space\n",
    "        self.obs_dim = env.observation_space.shape[0]\n",
    "\n",
    "        # actions placeholder\n",
    "        self.a_t_ph = tf.placeholder(dtype=tf.float32, \n",
    "                                     shape=[None, self.ac_dim])\n",
    "        # state placeholder\n",
    "        self.s_t_ph = tf.placeholder(dtype=tf.float32, \n",
    "                                     shape=[None, self.obs_dim])\n",
    "        # expected reward placeholder\n",
    "        self.rew_ph = tf.placeholder(dtype=tf.float32, \n",
    "                                     shape=[None])\n",
    "\n",
    "        # specifies whether the policy is stochastic\n",
    "        self.stochastic = stochastic\n",
    "\n",
    "        # policy that the agent executes during training/testing\n",
    "        self.policy = self.create_model(\n",
    "            args={\n",
    "                \"num_actions\": self.ac_dim,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"linear\": linear,\n",
    "                \"nonlinearity\": nonlinearity,\n",
    "                \"stochastic\": stochastic,\n",
    "                \"scope\": \"policy\",\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # define symbolic action\n",
    "        self.symbolic_action = self.action_op()\n",
    "\n",
    "        # initialize all variables\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # create saver to save model variables\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "    def create_model(self, args):\n",
    "        \n",
    "        \n",
    "        \"\"\"Create a model for your policy or other components.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        args : dict\n",
    "            model-specific arguments, with keys:\n",
    "              - \"stochastic\": True by default\n",
    "              - \"hidden_size\": Number of neurons in hidden layer\n",
    "              - \"num_actions\" number of output actions\n",
    "              - \"scope\": scope of the model\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tf.Variable\n",
    "            mean actions of the policy\n",
    "        tf.Variable \n",
    "            logstd of the policy actions\n",
    "        \"\"\"\n",
    "\n",
    "#################### Build Your Neural Network Here! ####################  \n",
    "        '''\n",
    "        input_size=self.obs_dim\n",
    "        hidden_size= args[\"hidden_size\"]\n",
    "        output_size= args[\"num_actions\"] \n",
    "        weights_0 = tf.Variable(tf.random_normal([self.obs_dim , hidden_size]))\n",
    "        bias_0 = tf.Variable(tf.random_normal([hidden_size]))\n",
    "        weights_1 = tf.Variable(tf.random_normal([hidden_size,hidden_size]))\n",
    "        bias_1 = tf.Variable(tf.random_normal([hidden_size]))\n",
    "        weights_2 = tf.Variable(tf.random_normal([hidden_size,output_size]))\n",
    "        bias_2 = tf.Variable(tf.random_normal([output_size]))\n",
    "        hidden_layer1= tf.nn.relu(tf.add(tf.matmul( self.s_t_ph , weights_0 ) , bias_0))\n",
    "        \n",
    "        hidden_layer2 =tf.nn.relu(tf.add(tf.matmul( hidden_layer1 , weights_1 ) , bias_1))\n",
    "        \n",
    "        output_mean = tf.add(tf.matmul( hidden_layer2 , weights_2), bias_2)\n",
    "        '''\n",
    "        input_size=self.obs_dim\n",
    "        hidden_size= args[\"hidden_size\"]\n",
    "        output_size= args[\"num_actions\"]\n",
    "        layer_1 = tf.layers.dense(self.s_t_ph, hidden_size, activation=tf.nn.relu)\n",
    "        layer_2 = tf.layers.dense(layer_1, hidden_size, activation=tf.nn.relu)\n",
    "        output_mean = tf.layers.dense(layer_2, output_size)\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "##########################################################################        \n",
    "\n",
    "        if args[\"stochastic\"]:\n",
    "            output_logstd =  tf.get_variable(name=\"action_logstd\",shape=[self.ac_dim],trainable=True)\n",
    "        else:\n",
    "            output_logstd = None\n",
    "\n",
    "        return output_mean, output_logstd\n",
    "    \n",
    "    def action_op(self):\n",
    "        \"\"\"\n",
    "        Create a symbolic expression that will be used to compute actions from observations.\n",
    "\n",
    "        When the policy is stochastic, the action follows \n",
    "\n",
    "            a_t = output_mean + exp(output_logstd) * z; z ~ N(0,1)\n",
    "        \"\"\"\n",
    "        if self.stochastic:\n",
    "            output_mean, output_logstd = self.policy\n",
    "\n",
    "            #################### Implement a stochastic policy here ####################        \n",
    "            # Implement a stochastic version of computing actions.       #\n",
    "            #                                                            #\n",
    "            # The action in a stochastic policy represented by           #\n",
    "            # a diagonal Gaussian distribution with mean \"M\" and log     #\n",
    "            # standard deviation \"logstd\" is computed as follows:        #\n",
    "            #                                                            #\n",
    "            #     a = M + exp(logstd) * z                                #\n",
    "            #                                                            #\n",
    "            # where z is a random normal value, i.e. z ~ N(0,1)          #\n",
    "            #                                                            #\n",
    "            # In order to generate numbers from a normal distribution,   #\n",
    "            # use the `tf.random_normal` function.                       #\n",
    "            ############################################################################ \n",
    "            symbolic_action = output_mean+tf.math.exp(output_logstd)*tf.random_normal(shape=[self.ac_dim])\n",
    "            \n",
    "        else:\n",
    "            symbolic_action, _ = self.policy\n",
    "        \n",
    "        return symbolic_action\n",
    "\n",
    "    def compute_action(self, obs):\n",
    "        \"\"\"Returns a list of actions for a given observation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        obs : np.ndarray\n",
    "            observations\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            actions by the policy for a given observation\n",
    "        \"\"\"\n",
    "        return self.sess.run(self.symbolic_action,feed_dict={self.s_t_ph: obs})\n",
    "\n",
    "    def rollout(self, s_mean=None, s_std=None):\n",
    "        \"\"\"Collect samples from one rollout of the policy.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            dictionary containing trajectory information for the rollout,\n",
    "            specifically containing keys for \"state\", \"action\", \"next_state\", \"reward\", and \"done\"\n",
    "        \"\"\"\n",
    "        states = []\n",
    "        next_states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        dones = []\n",
    "\n",
    "        # start a new rollout by re-setting the environment and collecting the initial state\n",
    "        state =  self.env.reset()\n",
    "\n",
    "        steps = 0\n",
    "        while True:\n",
    "            steps += 1\n",
    "\n",
    "            # compute the action given the state\n",
    "            if s_mean is not None and s_std is not None:\n",
    "                action = self.compute_action([(state - s_mean) / s_std])\n",
    "            else:\n",
    "                action = self.compute_action([state])\n",
    "            action = action[0]\n",
    "\n",
    "            # advance the environment once and collect the next state, reward, done, and info parameters from the environment\n",
    "            next_state, reward, done, info =  self.env.step(action)\n",
    "\n",
    "            # add to the samples list\n",
    "            states.append(state)\n",
    "            actions.append(action)\n",
    "            next_states.append(next_state)\n",
    "            rewards.append(reward)\n",
    "            dones.append(done)\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "            # if the environment returns a True for the done parameter,\n",
    "            # end the rollout before the time horizon is met\n",
    "            if done or steps > env._max_episode_steps:\n",
    "                break\n",
    "\n",
    "        # create the output trajectory\n",
    "        trajectory = {\"state\": np.array(states, dtype=np.float32),\n",
    "                      \"reward\": np.array(rewards, dtype=np.float32),\n",
    "                      \"action\": np.array(actions, dtype=np.float32),\n",
    "                      \"next_state\": np.array(next_states, dtype=np.float32),\n",
    "                      \"done\": np.array(dones, dtype=np.float32)}\n",
    "\n",
    "        return trajectory\n",
    "\n",
    "    def train(self, args):\n",
    "        \"\"\"Abstract training method.\n",
    "\n",
    "        This method will be filled in by algorithm-specific\n",
    "        training operations in subsequent problems.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        args : dict\n",
    "            algorithm-specific hyperparameters\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Tensorflow Interpretation\n",
    "\n",
    "In order to test your implementation of the **stochastic policy**, run the below cell. The task is to interpret the code you implemented in previous section. If you implement correctly, you can see the value_1 and value_2.\n",
    "\n",
    "***Question: How do you interpret value_1 and value_2 below cell?***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-5434944cbd4a>:126: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Mohammad\\anaconda3\\envs\\hw2\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "TEST_ENV = gym.make(\"Pendulum-v0\")\n",
    "\n",
    "alg = PolicyOpt(TEST_ENV, linear=False)\n",
    "input_1 = [[0, 1, 2]]\n",
    "value_1 = alg.sess.run(alg.policy[0], feed_dict={alg.s_t_ph: input_1})\n",
    "value_2 = alg.compute_action(input_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18702136]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05820368]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a5c3a05d569b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mac_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "print(self.ac_dim)  \n",
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Implement Policy Gradient\n",
    "\n",
    "In this section, we will implement REINFORCE algorithm presented in the lecture. As a review, the objective is optimize the parameters $\\theta$ of some policy $\\pi_\\theta$ so that the expected return\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\theta) = \\mathbb{E} \\bigg\\{ \\sum_{t=0}^T \\gamma^t r(s_{t},a_{t}) \\bigg\\}\n",
    "\\end{equation}\n",
    "\n",
    "is optimized. In this algorithm, this is done by calculating the gradient $\\nabla_\\theta J$ and applying a gradient descent method to find a better policy.\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta ' = \\theta + \\alpha \\nabla_\\theta J(\\theta)\n",
    "\\end{equation}\n",
    "\n",
    "In the lecture, we derive how we compute $\\nabla_{\\theta} J(\\theta)$. We can rewrite our policy gradient as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_\\theta J (\\theta) \\approx \\frac{1}{N} \\sum_{i=0}^{N} \\bigg( \\sum_{t=0}^{T} \\nabla_\\theta \\log \\pi_\\theta (a_{it} | s_{it}) \\bigg) \\bigg( \\sum_{t=0}^T \\gamma^{t}r_i(t) \\bigg)\n",
    "\\end{equation}\n",
    "\n",
    "Finally, taking into account the causality principle discussed in class, we are able to simplifiy the gradient estimate such as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_\\theta J (\\theta) \\approx \\frac{1}{N} \\sum_{i=0}^{N} \\sum_{t=0}^{T} \\nabla_\\theta \\log \\pi_\\theta (a_{it} | s_{it}) \\sum_{t'=t}^T \\gamma^{t'-t}r_i(t')\n",
    "\\end{equation}\n",
    "\n",
    "You will be implementing final expression in this assignment!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of REINFOCE algorithm follows:\n",
    "\n",
    "1. Collect samples from current policy $\\pi_\\theta(s)$ by executing rollouts of the environment.\n",
    "2. Calculate an estimate for the expected return at state $s_t$. \n",
    "3. Compute the log-likelihood of each action that was performed by the policy at every given step.\n",
    "4. Estimate the gradient and update the parameters of policy using gradient-based technique.\n",
    "5. Repeat steps 1-4 for a number of training iterations.\n",
    "\n",
    "***Your task*** is to fill out the skeleton code for REINFORCE algorithm,\n",
    "\n",
    "1. Complete the 'log_likelihoods' method to compute gradient of policy, $\\nabla_{\\theta}\\pi_{\\theta}$ for diagonal Guassian policy. \n",
    "\n",
    "2. Complete the 'compute_expected_return' method to calculate the reward-to-go, $\\sum_{t^{\\prime}=t}^{T}$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_probability'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-de160653585e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_probability\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_probability\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_probability'"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "class REINFORCE(PolicyOpt):\n",
    "\n",
    "    def train(self, num_iterations=1000, steps_per_iteration=1000, learning_rate=int(1e-4), gamma=0.95, \n",
    "              **kwargs):\n",
    "        \"\"\"Perform the REINFORE training operation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_iterations : int\n",
    "            number of training iterations\n",
    "        steps_per_iteration : int\n",
    "            number of individual samples collected every training iteration\n",
    "        learning_rate : float\n",
    "            optimizer learning rate\n",
    "        gamma : float\n",
    "            discount rate\n",
    "        kwargs : dict\n",
    "            additional arguments\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of float\n",
    "            average return per iteration\n",
    "        \"\"\"\n",
    "        # set the discount as an attribute\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # set the learning rate as an attribute\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # create a symbolic expression to compute the log-likelihoods \n",
    "        log_likelihoods = self.log_likelihoods()\n",
    "\n",
    "        # create a symbolic expression for updating the parameters of your policy\n",
    "        self.opt, self.opt_baseline = self.define_updates(log_likelihoods)\n",
    "        \n",
    "        # initialize all variables\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "        # average return per training iteration\n",
    "        ret_per_iteration = []\n",
    "        \n",
    "        samples = []\n",
    "        for i in range(num_iterations):\n",
    "            \n",
    "            # collect samples from the current policy\n",
    "            samples.clear()\n",
    "            steps_so_far = 0\n",
    "            while steps_so_far < steps_per_iteration:\n",
    "                new_samples = self.rollout()\n",
    "                steps_so_far += new_samples[\"action\"].shape[0]\n",
    "                samples.append(new_samples)\n",
    "\n",
    "            # compute the expected returns\n",
    "            v_s = self.compute_expected_return(samples)\n",
    "\n",
    "            # compute and apply the gradients\n",
    "            self.call_updates(log_likelihoods, samples, v_s, **kwargs)\n",
    "\n",
    "            # compute the average cumulative return per iteration\n",
    "            average_rew = np.mean([sum(s[\"reward\"]) for s in samples])\n",
    "\n",
    "            # display iteration statistics\n",
    "            print(\"Iteration {} return: {}\".format(i, average_rew))\n",
    "            ret_per_iteration.append(average_rew)\n",
    "\n",
    "        return ret_per_iteration\n",
    "\n",
    "    def log_likelihoods(self):\n",
    "        \"\"\"Create a tensorflow operation that computes the log-likelihood \n",
    "        of each performed action.\n",
    "        \"\"\"\n",
    "        \n",
    "        output_mean, output_logstd = self.policy\n",
    "\n",
    "        ##############################################################\n",
    "        # Create a tf operation to compute the log-likelihood of     #\n",
    "        # each action that was performed by the policy               #\n",
    "        #                                                            #\n",
    "        # The log likelihood in the continuous case where the policy #\n",
    "        # is expressed by a multivariate gaussian can be computing   #\n",
    "        # using the tensorflow object:                               #\n",
    "        #                                                            #\n",
    "        #    p = tfp.distributions.MultivariateNormalDiag(           #\n",
    "        #        loc=...,                                            #\n",
    "        #        scale_diag=...,                                     #\n",
    "        #    )                                                       #\n",
    "        #                                                            #\n",
    "        # This method takes as input a mean (loc) and standard       #\n",
    "        # deviation (scale_diag), and then can be used to compute    #\n",
    "        # the log-likelihood of a variable as follows:               #\n",
    "        #                                                            #\n",
    "        #    log_likelihoods = p.log_prob(...)                       #\n",
    "        #                                                            #\n",
    "        # For this operation, you will want to use placeholders      #\n",
    "        # created in the __init__ method of problem 1.               #\n",
    "        ##############################################################\n",
    "\n",
    "        p = tfp.distributions.MultivariateNormalDiag(loc=output_mean,scale_diag=tf.math.exp(output_logstd))\n",
    "        log_likelihoods = p.log_prob(self.a_t_ph)  #check this also tried--> self.symbolic_action or self.a_t_ph\n",
    "\n",
    "        return log_likelihoods\n",
    "\n",
    "    def compute_expected_return(self, samples):\n",
    "        \"\"\"Compute the expected return from a given starting state.\n",
    "        This is done by using the reward-to-go method.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rewards : list of list of float\n",
    "            a list of N trajectories, with each trajectory contain T \n",
    "            returns values (one for each step in the trajectory)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of float, or np.ndarray\n",
    "            expected returns for each step in each trajectory\n",
    "        \"\"\"\n",
    "        rewards = [s[\"reward\"] for s in samples]\n",
    "\n",
    "        ##############################################################\n",
    "        # Estimate the expected return from any given starting state #\n",
    "        # using the reward-to-go method.                             #\n",
    "        #                                                            #\n",
    "        # Using this method, the reward is estimated at every step   #\n",
    "        # of the trajectory as follows:                              #\n",
    "        #                                                            #\n",
    "        #   r = sum_{t'=t}^T gamma^(t'-t) * r_{t'}                   #\n",
    "        #                                                            #\n",
    "        # where T is the time horizon at t is the index of the       #\n",
    "        # current reward in the trajectory. For example, for a given #\n",
    "        # set of rewards r = [1,1,1,1] and discount rate gamma = 1,  #\n",
    "        # the expected reward-to-go would be:                        #\n",
    "        #                                                            #\n",
    "        #   v_s = [4, 3, 2, 1]                                       #\n",
    "        #                                                            #\n",
    "        # You will be able to test this in one of the cells below!   #\n",
    "        ##############################################################\n",
    "        v_s=[]\n",
    "        for r in rewards:\n",
    "            v_z=np.zeros_like(r)\n",
    "            for t in range(len(r)):\n",
    "                for w in range(len(r)):\n",
    "                    if t<=w:\n",
    "                        v_z[t]+=r[w]\n",
    "                v_s.append(v_z[t])              \n",
    "        return v_s\n",
    "        \n",
    "\n",
    "    def define_updates(self, log_likelihoods):\n",
    "        \"\"\"Create a tensorflow operation to update the parameters of \n",
    "        your policy.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        log_likelihoods : tf.Operation\n",
    "            the symbolic expression you created to estimate the log \n",
    "            likelihood of a set of actions\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tf.Operation\n",
    "            a tensorflow operation for computing and applying the \n",
    "            gradients to the parameters of the policy\n",
    "        None\n",
    "            the second component is used in problem 2.b, please ignore \n",
    "            for this problem\n",
    "        \"\"\"\n",
    "\n",
    "        loss = - tf.reduce_mean(tf.multiply(log_likelihoods, self.rew_ph))\n",
    "        opt = tf.train.AdamOptimizer(self.learning_rate).minimize(loss)\n",
    "\n",
    "        return opt, None\n",
    "\n",
    "    def call_updates(self, log_likelihoods, samples, v_s, **kwargs):\n",
    "        \"\"\"Apply the gradient update methods in a tensorflow session.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        log_likelihoods: tf.Operation\n",
    "            the symbolic expression you created to estimate the log \n",
    "            likelihood of a set of actions\n",
    "        samples : list of dict\n",
    "            a list of N trajectories, with each trajectory containing \n",
    "            a dictionary of trajectory data (see self.rollout)\n",
    "        v_s : list of float, or np.ndarray\n",
    "            the estimated expected returns from your\n",
    "            `comput_expected_return` function \n",
    "        kwargs : dict\n",
    "            additional arguments (used in question 3)\n",
    "        \"\"\"\n",
    "        # concatenate the states\n",
    "        states = np.concatenate([s[\"state\"] for s in samples])\n",
    "\n",
    "        # concatenate the actions\n",
    "        actions = np.concatenate([s[\"action\"] for s in samples])\n",
    "\n",
    "        # execute the optimization step\n",
    "        self.sess.run(self.opt, feed_dict={self.s_t_ph: states,\n",
    "                                           self.a_t_ph: actions,\n",
    "                                           self.rew_ph: v_s})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your 'log_likelihoods' method by running below cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'REINFORCE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-38595749768f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0malg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mREINFORCE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEST_ENV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstochastic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlog_likelihoods\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_likelihoods\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# collect a sample output for a given input state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'REINFORCE' is not defined"
     ]
    }
   ],
   "source": [
    "alg = REINFORCE(TEST_ENV, stochastic=True)\n",
    "\n",
    "log_likelihoods = alg.log_likelihoods()\n",
    "\n",
    "# collect a sample output for a given input state\n",
    "input_s = [[0, 0, 0], [0, 1, 2], [1, 2, 3]]\n",
    "input_a = [[0], [1], [2]]\n",
    "\n",
    "# Check\n",
    "computed = alg.sess.run(log_likelihoods, feed_dict={alg.a_t_ph: input_a, alg.s_t_ph: input_s})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your 'compute_expected_return' by running below cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'REINFORCE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-4baae052544a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 1. Test the non-normalized case\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0malg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mREINFORCE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEST_ENV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstochastic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m input_1 = [{\"reward\": [1, 1, 1, 1]},\n",
      "\u001b[1;31mNameError\u001b[0m: name 'REINFORCE' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Test the non-normalized case\n",
    "alg = REINFORCE(TEST_ENV, stochastic=True)\n",
    "alg.gamma = 1.0\n",
    "    \n",
    "input_1 = [{\"reward\": [1, 1, 1, 1]},\n",
    "           {\"reward\": [1, 1, 1, 1]}]\n",
    "vs_1 = alg.compute_expected_return(samples=input_1)\n",
    "ans_1 = np.array([4, 3, 2, 1, 4, 3, 2, 1])\n",
    "\n",
    "if np.linalg.norm(vs_1 - ans_1) < 1e-3:\n",
    "    print('Great job!')\n",
    "else:\n",
    "    print('Check your implementation (compute_expected_return)')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Testing your algorithm\n",
    "\n",
    "When you are ready, test your policy gradient algorithms on the *Pendulum-v0* environment in the cell below. *Pendulum-v0* environment is similar to *off-shore wind power*, the goal here is to maintain the Pendulum is upright using control input. The best policy should get around -200 scores. ***Your task*** is to run your REINFORCE algorithm and plot the result!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Training Run 0 ====\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'REINFORCE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-bc38a950b21a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUM_TRIALS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n==== Training Run {} ====\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0malg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mREINFORCE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstochastic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.95\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'REINFORCE' is not defined"
     ]
    }
   ],
   "source": [
    "# set this number as 1 for testing your algorithm, and 3 for plotting\n",
    "NUM_TRIALS = 3\n",
    "\n",
    "# ===========================================================================\n",
    "# Do not modify below line\n",
    "# ===========================================================================\n",
    "\n",
    "# we will test the algorithms on the Pendulum-v0 gym environment\n",
    "import gym\n",
    "env = gym.make(\"Pendulum-v0\")\n",
    "\n",
    "# train on the REINFORCE algorithm\n",
    "import numpy as np\n",
    "r = []\n",
    "for i in range(NUM_TRIALS):\n",
    "    print(\"\\n==== Training Run {} ====\".format(i))\n",
    "    alg = REINFORCE(env, stochastic=True)\n",
    "    res = alg.train(learning_rate=0.005, gamma=0.95, num_iterations=500, steps_per_iteration=15000)\n",
    "    r.append(np.array(res))\n",
    "    alg = None\n",
    "\n",
    "# save results\n",
    "np.savetxt(\"InvertedPendulum_results.csv\", np.array(r), delimiter=\",\")\n",
    "\n",
    "def render(self, mode='human'):\n",
    "        if self.viewer is None:\n",
    "            from gym.envs.classic_control import rendering\n",
    "            self.viewer = rendering.Viewer(500, 500)\n",
    "            self.viewer.set_bounds(-2.2, 2.2, -2.2, 2.2)\n",
    "            rod = rendering.make_capsule(1, .2)\n",
    "            rod.set_color(.8, .3, .3)\n",
    "            self.pole_transform = rendering.Transform()\n",
    "            rod.add_attr(self.pole_transform)\n",
    "            self.viewer.add_geom(rod)\n",
    "            axle = rendering.make_circle(.05)\n",
    "            axle.set_color(0, 0, 0)\n",
    "            self.viewer.add_geom(axle)\n",
    "            fname = path.join(path.dirname(__file__), \"assets/clockwise.png\")\n",
    "            self.img = rendering.Image(fname, 1., 1.)\n",
    "            self.imgtrans = rendering.Transform()\n",
    "            self.img.add_attr(self.imgtrans)\n",
    "\n",
    "        self.viewer.add_onetime(self.img)\n",
    "        self.pole_transform.set_rotation(self.state[0] + np.pi / 2)\n",
    "        if self.last_u:\n",
    "            self.imgtrans.scale = (-self.last_u / 2, np.abs(self.last_u) / 2)\n",
    "\n",
    "        return self.viewer.render(return_rgb_array=mode == 'rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.89490748  0.44625173  0.52276955]\n",
      "[[-0.15607424]]\n",
      "[[-0.91273373]\n",
      " [ 0.40855488]\n",
      " [ 0.83404726]]\n",
      "[[-0.91912967]]\n",
      "[[-0.9320593]\n",
      " [ 0.3623058]\n",
      " [ 1.0025939]]\n",
      "[[2.35916]]\n",
      "[[-0.957663  ]\n",
      " [ 0.28789163]\n",
      " [ 1.5743229 ]]\n",
      "[[1.6052735]]\n",
      "[[-0.9819148 ]\n",
      " [ 0.18932335]\n",
      " [ 2.0310326 ]]\n",
      "[[-2.2990305]]\n",
      "[[-0.99531645]\n",
      " [ 0.09667049]\n",
      " [ 1.8730251 ]]\n",
      "[[4.1905327]]\n",
      "[[-0.99988055]\n",
      " [-0.015454  ]\n",
      " [ 2.2455277 ]]\n",
      "[[-0.59435296]]\n",
      "[[-0.99248254]\n",
      " [-0.12238626]\n",
      " [ 2.144784  ]]\n",
      "[[2.7757964]]\n",
      "[[-0.97125626]\n",
      " [-0.23803642]\n",
      " [ 2.3529944 ]]\n",
      "[[2.87871]]\n",
      "[[-0.9344564 ]\n",
      " [-0.35607752]\n",
      " [ 2.474467  ]]\n",
      "[[-0.6161399]]\n",
      "[[-0.89165145]\n",
      " [-0.4527225 ]\n",
      " [ 2.114988  ]]\n",
      "[[-1.9344916]]\n",
      "[[-0.85560393]\n",
      " [-0.51763105]\n",
      " [ 1.4852724 ]]\n",
      "[[2.992885]]\n",
      "[[-0.8173891 ]\n",
      " [-0.57608604]\n",
      " [ 1.3970491 ]]\n",
      "[[2.1057305]]\n",
      "[[-0.779342  ]\n",
      " [-0.62659883]\n",
      " [ 1.2649845 ]]\n",
      "[[0.66044974]]\n",
      "[[-0.75056046]\n",
      " [-0.66080177]\n",
      " [ 0.8941028 ]]\n",
      "[[-2.4198895]]\n",
      "[[-0.7472969 ]\n",
      " [-0.6644903 ]\n",
      " [ 0.09850156]]\n",
      "[[0.9565785]]\n",
      "[[-0.75575346]\n",
      " [-0.65485626]\n",
      " [-0.2563794 ]]\n",
      "[[2.1419132]]\n",
      "[[-0.7702161 ]\n",
      " [-0.637783  ]\n",
      " [-0.44752175]]\n",
      "[[5.686864]]\n",
      "[[-0.78979385]\n",
      " [-0.6133724 ]\n",
      " [-0.6258592 ]]\n",
      "[[-5.4817996]]\n",
      "[[-0.83036774]\n",
      " [-0.55721575]\n",
      " [-1.3858887 ]]\n",
      "[[0.8996049]]\n",
      "[[-0.8739204]\n",
      " [-0.4860691]\n",
      " [-1.6688597]]\n",
      "[[1.1505663]]\n",
      "[[-0.91529983]\n",
      " [-0.4027732 ]\n",
      " [-1.8608266 ]]\n",
      "[[-2.349179]]\n",
      "[[-0.95784277]\n",
      " [-0.28729284]\n",
      " [-2.4629066 ]]\n",
      "[[-2.2135687]]\n",
      "[[-0.9898668 ]\n",
      " [-0.14199887]\n",
      " [-2.9783764 ]]\n",
      "[[-5.9858046]]\n",
      "[[-0.9996419 ]\n",
      " [ 0.02676016]\n",
      " [-3.3848755 ]]\n",
      "[[-2.1190336]]\n",
      "[[-0.9780302 ]\n",
      " [ 0.20846336]\n",
      " [-3.6648054 ]]\n",
      "[[-1.3417666]]\n",
      "[[-0.92280805]\n",
      " [ 0.38526005]\n",
      " [-3.7097232 ]]\n",
      "[[-0.608992]]\n",
      "[[-0.84130913]\n",
      " [ 0.54055434]\n",
      " [-3.5121272 ]]\n",
      "[[-1.6261027]]\n",
      "[[-0.7393936 ]\n",
      " [ 0.67327344]\n",
      " [-3.350627  ]]\n",
      "[[-3.905655]]\n",
      "[[-0.6248081]\n",
      " [ 0.7807784]\n",
      " [-3.145672 ]]\n",
      "[[-3.863595]]\n",
      "[[-0.5071556]\n",
      " [ 0.8618545]\n",
      " [-2.8600883]]\n",
      "[[-2.8519382]]\n",
      "[[-0.3951181 ]\n",
      " [ 0.91863036]\n",
      " [-2.5136976 ]]\n",
      "[[-3.1812842]]\n",
      "[[-0.29548216]\n",
      " [ 0.95534825]\n",
      " [-2.1247249 ]]\n",
      "[[-2.4467924]]\n",
      "[[-0.21290724]\n",
      " [ 0.9770724 ]\n",
      " [-1.7082137 ]]\n",
      "[[1.5932499]]\n",
      "[[-0.17679416]\n",
      " [ 0.98424786]\n",
      " [-0.7364218 ]]\n",
      "[[0.19130675]]\n",
      "[[-0.17829297]\n",
      " [ 0.98397744]\n",
      " [ 0.03046006]]\n",
      "[[-0.9297294]]\n",
      "[[-0.20914501]\n",
      " [ 0.97788465]\n",
      " [ 0.6289837 ]]\n",
      "[[-1.2971286]]\n",
      "[[-0.26585624]\n",
      " [ 0.9640127 ]\n",
      " [ 1.1678278 ]]\n",
      "[[4.162729]]\n",
      "[[-0.36965147]\n",
      " [ 0.9291705 ]\n",
      " [ 2.1908374 ]]\n",
      "[[-1.6944239]]\n",
      "[[-0.4884491]\n",
      " [ 0.8725924]\n",
      " [ 2.6335516]]\n",
      "[[-2.4843993]]\n",
      "[[-0.61288875]\n",
      " [ 0.79016924]\n",
      " [ 2.9879959 ]]\n",
      "[[3.317591]]\n",
      "[[-0.75374514]\n",
      " [ 0.65716684]\n",
      " [ 3.8806229 ]]\n",
      "[[-2.2757359]]\n",
      "[[-0.87109   ]\n",
      " [ 0.49112347]\n",
      " [ 4.073498  ]]\n",
      "[[1.0681404]]\n",
      "[[-0.96014494]\n",
      " [ 0.27950257]\n",
      " [ 4.6020613 ]]\n",
      "[[3.2847266]]\n",
      "[[-0.9996166 ]\n",
      " [ 0.02768798]\n",
      " [ 5.111688  ]]\n",
      "[[0.78870213]]\n",
      "[[-0.9725501 ]\n",
      " [-0.23269364]\n",
      " [ 5.250759  ]]\n",
      "[[3.686503]]\n",
      "[[-0.8758228 ]\n",
      " [-0.48263285]\n",
      " [ 5.376239  ]]\n",
      "[[1.0272045]]\n",
      "[[-0.7234044 ]\n",
      " [-0.69042456]\n",
      " [ 5.168345  ]]\n",
      "[[0.03897199]]\n",
      "[[-0.5445915]\n",
      " [-0.8387014]\n",
      " [ 4.656372 ]]\n",
      "[[0.79613096]]\n",
      "[[-0.3602759]\n",
      " [-0.9328458]\n",
      " [ 4.1467657]]\n",
      "[[-0.3704151]]\n",
      "[[-0.19767454]\n",
      " [-0.9802677 ]\n",
      " [ 3.3915691 ]]\n",
      "[[-0.53342754]]\n",
      "[[-0.07010996]\n",
      " [-0.9975393 ]\n",
      " [ 2.5763543 ]]\n",
      "[[-1.2948537]]\n",
      "[[ 0.01153063]\n",
      " [-0.99993354]\n",
      " [ 1.6339717 ]]\n",
      "[[4.308887]]\n",
      "[[ 0.07067317]\n",
      " [-0.9974995 ]\n",
      " [ 1.1840215 ]]\n",
      "[[0.24915689]]\n",
      "[[ 0.09425553]\n",
      " [-0.995548  ]\n",
      " [ 0.47327036]]\n",
      "[[-0.77434474]]\n",
      "[[ 0.0748487 ]\n",
      " [-0.9971949 ]\n",
      " [-0.38954234]]\n",
      "[[-2.0160396]]\n",
      "[[ 0.003047  ]\n",
      " [-0.99999535]\n",
      " [-1.4374386 ]]\n",
      "[[-4.0382924]]\n",
      "[[-0.1210271]\n",
      " [-0.9926492]\n",
      " [-2.4874353]]\n",
      "[[-1.256304]]\n",
      "[[-0.2881967]\n",
      " [-0.9575712]\n",
      " [-3.420368 ]]\n",
      "[[1.9589877]]\n",
      "[[-0.4658351 ]\n",
      " [-0.88487154]\n",
      " [-3.8446982 ]]\n",
      "[[-3.6963637]]\n",
      "[[-0.66313213]\n",
      " [-0.7485023 ]\n",
      " [-4.808352  ]]\n",
      "[[-0.5611911]]\n",
      "[[-0.8402211]\n",
      " [-0.5422439]\n",
      " [-5.4539075]]\n",
      "[[2.0936446]]\n",
      "[[-0.9567801 ]\n",
      " [-0.29081255]\n",
      " [-5.5605903 ]]\n",
      "[[-3.0466359]]\n",
      "[[-0.9999608 ]\n",
      " [ 0.00885895]\n",
      " [-6.0786996 ]]\n",
      "[[-2.5055113]]\n",
      "[[-0.94686174]\n",
      " [ 0.32164082]\n",
      " [-6.3720555 ]]\n",
      "[[-5.701767]]\n",
      "[[-0.79668665]\n",
      " [ 0.6043925 ]\n",
      " [-6.430825  ]]\n",
      "[[2.8814821]]\n",
      "[[-0.5955232]\n",
      " [ 0.8033381]\n",
      " [-5.677531 ]]\n",
      "[[-1.3674667]]\n",
      "[[-0.3652575 ]\n",
      " [ 0.93090653]\n",
      " [-5.280147  ]]\n",
      "[[-1.7723099]]\n",
      "[[-0.13113995]\n",
      " [ 0.9913639 ]\n",
      " [-4.8478136 ]]\n",
      "[[-7.3966174]]\n",
      "[[ 0.08857948]\n",
      " [ 0.99606913]\n",
      " [-4.4042907 ]]\n",
      "[[6.6097155]]\n",
      "[[ 0.25375238]\n",
      " [ 0.9672692 ]\n",
      " [-3.3572388 ]]\n",
      "[[0.6405824]]\n",
      "[[ 0.3740225]\n",
      " [ 0.9274196]\n",
      " [-2.5356994]]\n",
      "[[2.591872]]\n",
      "[[ 0.44426104]\n",
      " [ 0.8958974 ]\n",
      " [-1.5401347 ]]\n",
      "[[1.4599463]]\n",
      "[[ 0.47310355]\n",
      " [ 0.88100684]\n",
      " [-0.64921963]]\n",
      "[[3.2324746]]\n",
      "[[0.45932353]\n",
      " [0.88826907]\n",
      " [0.31153542]]\n",
      "[[1.1604081]]\n",
      "[[0.407435  ]\n",
      " [0.91323423]\n",
      " [1.1517985 ]]\n",
      "[[1.6755202]]\n",
      "[[0.31004554]\n",
      " [0.9507217 ]\n",
      " [2.0880523 ]]\n",
      "[[-0.52002054]]\n",
      "[[0.17813066]\n",
      " [0.9840068 ]\n",
      " [2.7230906 ]]\n",
      "[[-2.1938348]]\n",
      "[[0.02103002]\n",
      " [0.99977887]\n",
      " [3.1610959 ]]\n",
      "[[0.14185528]]\n",
      "[[-0.17467815]\n",
      " [ 0.9846256 ]\n",
      " [ 3.9322083 ]]\n",
      "[[-1.2591705]]\n",
      "[[-0.38911343]\n",
      " [ 0.92118984]\n",
      " [ 4.481802  ]]\n",
      "[[-0.48180142]]\n",
      "[[-0.60891354]\n",
      " [ 0.7932366 ]\n",
      " [ 5.1004243 ]]\n",
      "[[-2.3750286]]\n",
      "[[-0.7982943 ]\n",
      " [ 0.60226756]\n",
      " [ 5.395352  ]]\n",
      "[[3.3934953]]\n",
      "[[-0.9430923 ]\n",
      " [ 0.33253103]\n",
      " [ 6.147053  ]]\n",
      "[[0.39382806]]\n",
      "[[-0.99986863]\n",
      " [ 0.01620904]\n",
      " [ 6.455525  ]]\n",
      "[[0.6166632]]\n",
      "[[-0.9517831 ]\n",
      " [-0.30677176]\n",
      " [ 6.560181  ]]\n",
      "[[0.6462461]]\n",
      "[[-0.8061669]\n",
      " [-0.5916882]\n",
      " [ 6.427039 ]]\n",
      "[[-7.381109]]\n",
      "[[-0.60795426]\n",
      " [-0.793972  ]\n",
      " [ 5.683273  ]]\n",
      "[[1.0229449]]\n",
      "[[-0.3815013]\n",
      " [-0.9243683]\n",
      " [ 5.2412353]]\n",
      "[[0.6943954]]\n",
      "[[-0.15814719]\n",
      " [-0.98741555]\n",
      " [ 4.652118  ]]\n",
      "[[0.5067483]]\n",
      "[[ 0.04055342]\n",
      " [-0.9991774 ]\n",
      " [ 3.9875689 ]]\n",
      "[[-0.9203115]]\n",
      "[[ 0.1943271 ]\n",
      " [-0.98093677]\n",
      " [ 3.1001391 ]]\n",
      "[[4.337885]]\n",
      "[[ 0.32290098]\n",
      " [-0.94643277]\n",
      " [ 2.6644366 ]]\n",
      "[[1.232357]]\n",
      "[[ 0.42210516]\n",
      " [-0.9065469 ]\n",
      " [ 2.1394656 ]]\n",
      "[[-3.4099984]]\n",
      "[[ 0.47392595]\n",
      " [-0.8805647 ]\n",
      " [ 1.1595554 ]]\n",
      "[[3.284764]]\n",
      "[[ 0.50872266]\n",
      " [-0.86093044]\n",
      " [ 0.799132  ]]\n",
      "[[0.4830842]]\n",
      "[[ 0.5184141 ]\n",
      " [-0.8551297 ]\n",
      " [ 0.22589678]]\n",
      "[[2.6742837]]\n",
      "[[ 0.51346916]\n",
      " [-0.85810804]\n",
      " [-0.11545041]]\n",
      "[[3.8641443]]\n",
      "[[ 0.4936407 ]\n",
      " [-0.8696659 ]\n",
      " [-0.45903134]]\n",
      "[[-2.4372652]]\n",
      "[[ 0.43109578]\n",
      " [-0.90230614]\n",
      " [-1.4112809 ]]\n",
      "[[2.1130188]]\n",
      "[[ 0.34881473]\n",
      " [-0.9371917 ]\n",
      " [-1.7880106 ]]\n",
      "[[-0.9951774]]\n",
      "[[ 0.22242108]\n",
      " [-0.9749507 ]\n",
      " [-2.6401808 ]]\n",
      "[[-2.9321156]]\n",
      "[[ 0.04071589]\n",
      " [-0.9991708 ]\n",
      " [-3.6713939 ]]\n",
      "[[0.20182109]]\n",
      "[[-0.17784658]\n",
      " [-0.9840582 ]\n",
      " [-4.3904986 ]]\n",
      "[[-1.1018469]]\n",
      "[[-0.42909318]\n",
      " [-0.90326023]\n",
      " [-5.2938194 ]]\n",
      "[[-1.5687606]]\n",
      "[[-0.684427  ]\n",
      " [-0.72908133]\n",
      " [-6.2065787 ]]\n",
      "[[2.0616815]]\n",
      "[[-0.8802966]\n",
      " [-0.4744237]\n",
      " [-6.45339  ]]\n",
      "[[-2.6242344]]\n",
      "[[-0.990376  ]\n",
      " [-0.13840315]\n",
      " [-7.1092076 ]]\n",
      "[[2.870011]]\n",
      "[[-0.97869265]\n",
      " [ 0.20533067]\n",
      " [-6.91301   ]]\n",
      "[[1.3219616]]\n",
      "[[-0.8603515 ]\n",
      " [ 0.50970113]\n",
      " [-6.5607176 ]]\n",
      "[[3.007325]]\n",
      "[[-0.6757906]\n",
      " [ 0.7370937]\n",
      " [-5.878442 ]]\n",
      "[[-3.8498118]]\n",
      "[[-0.44462517]\n",
      " [ 0.8957167 ]\n",
      " [-5.625622  ]]\n",
      "[[-0.19082317]]\n",
      "[[-0.21005663]\n",
      " [ 0.9776892 ]\n",
      " [-4.9824576 ]]\n",
      "[[2.32919]]\n",
      "[[-0.01417284]\n",
      " [ 0.99989957]\n",
      " [-3.9491906 ]]\n",
      "[[4.532459]]\n",
      "[[ 0.13041739]\n",
      " [ 0.9914592 ]\n",
      " [-2.8992658 ]]\n",
      "[[-5.0682883]]\n",
      "[[ 0.25086477]\n",
      " [ 0.96802217]\n",
      " [-2.4556713 ]]\n",
      "[[-0.03122377]]\n",
      "[[ 0.33376083]\n",
      " [ 0.94265777]\n",
      " [-1.7343383 ]]\n",
      "[[-0.9217727]]\n",
      "[[ 0.38810173]\n",
      " [ 0.92161655]\n",
      " [-1.1656108 ]]\n",
      "[[7.0551953]]\n",
      "[[ 0.3961233 ]\n",
      " [ 0.91819733]\n",
      " [-0.1743983 ]]\n",
      "[[-4.542815]]\n",
      "[[0.38626456]\n",
      " [0.922388  ]\n",
      " [0.2142497 ]]\n",
      "[[-1.2513536]]\n",
      "[[0.3528932]\n",
      " [0.9356636]\n",
      " [0.7183378]]\n",
      "[[0.7077195]]\n",
      "[[0.28053293]\n",
      " [0.9598444 ]\n",
      " [1.5262434 ]]\n",
      "[[-1.0694116]]\n",
      "[[0.17909211]\n",
      " [0.9838323 ]\n",
      " [2.085715  ]]\n",
      "[[-1.3325561]]\n",
      "[[0.04885881]\n",
      " [0.9988057 ]\n",
      " [2.6237059 ]]\n",
      "[[-3.36566]]\n",
      "[[-0.10457072]\n",
      " [ 0.99451745]\n",
      " [ 3.0728102 ]]\n",
      "[[0.51422447]]\n",
      "[[-0.2950939 ]\n",
      " [ 0.95546824]\n",
      " [ 3.895832  ]]\n",
      "[[2.231398]]\n",
      "[[-0.51856816]\n",
      " [ 0.8550363 ]\n",
      " [ 4.912433  ]]\n",
      "[[1.1254523]]\n",
      "[[-0.73880935]\n",
      " [ 0.6739145 ]\n",
      " [ 5.722528  ]]\n",
      "[[0.5535691]]\n",
      "[[-0.9114734 ]\n",
      " [ 0.41135907]\n",
      " [ 6.3109994 ]]\n",
      "[[-1.3882627]]\n",
      "[[-0.994661  ]\n",
      " [ 0.10319655]\n",
      " [ 6.411279  ]]\n",
      "[[-2.8560185]]\n",
      "[[-0.9788461]\n",
      " [-0.2045981]\n",
      " [ 6.1886764]]\n",
      "[[1.1062571]]\n",
      "[[-0.8697448 ]\n",
      " [-0.49350184]\n",
      " [ 6.201166  ]]\n",
      "[[-4.379534]]\n",
      "[[-0.70195085]\n",
      " [-0.7122254 ]\n",
      " [ 5.5310397 ]]\n",
      "[[-0.17277908]]\n",
      "[[-0.50517553]\n",
      " [-0.8630166 ]\n",
      " [ 4.970954  ]]\n",
      "[[3.1176078]]\n",
      "[[-0.29399213]\n",
      " [-0.95580786]\n",
      " [ 4.6236916 ]]\n",
      "[[-1.2970798]]\n",
      "[[-0.11254826]\n",
      " [-0.99364626]\n",
      " [ 3.7122736 ]]\n",
      "[[2.171655]]\n",
      "[[ 0.05054323]\n",
      " [-0.9987219 ]\n",
      " [ 3.2670388 ]]\n",
      "[[-1.5371556]]\n",
      "[[ 0.16418928]\n",
      " [-0.98642886]\n",
      " [ 2.287424  ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.6388878]]\n",
      "[[ 0.23529737]\n",
      " [-0.9719234 ]\n",
      " [ 1.4517694 ]]\n",
      "[[-1.598219]]\n",
      "[[ 0.25870293]\n",
      " [-0.9659569 ]\n",
      " [ 0.48309392]]\n",
      "[[0.3370178]]\n",
      "[[ 0.24947508]\n",
      " [-0.9683812 ]\n",
      " [-0.19082117]]\n",
      "[[-0.45750487]]\n",
      "[[ 0.20146298]\n",
      " [-0.9794961 ]\n",
      " [-0.9857328 ]]\n",
      "[[0.2907179]]\n",
      "[[ 0.11873304]\n",
      " [-0.99292624]\n",
      " [-1.6767472 ]]\n",
      "[[1.4773194]]\n",
      "[[ 0.00902165]\n",
      " [-0.9999593 ]\n",
      " [-2.199844  ]]\n",
      "[[2.6446762]]\n",
      "[[-0.1231554]\n",
      " [-0.9923874]\n",
      " [-2.6498134]]\n",
      "[[-1.8627588]]\n",
      "[[-0.30233812]\n",
      " [-0.95320076]\n",
      " [-3.6735177 ]]\n",
      "[[-2.0766673]]\n",
      "[[-0.515478 ]\n",
      " [-0.8569028]\n",
      " [-4.6884184]]\n",
      "[[1.3467833]]\n",
      "[[-0.7159748 ]\n",
      " [-0.69812614]\n",
      " [-5.129078  ]]\n",
      "[[-0.41491225]]\n",
      "[[-0.883726  ]\n",
      " [-0.46800464]\n",
      " [-5.7149096 ]]\n",
      "[[0.6816294]]\n",
      "[[-0.9822211]\n",
      " [-0.1877276]\n",
      " [-5.963669 ]]\n",
      "[[0.15683976]]\n",
      "[[-0.99337196]\n",
      " [ 0.11494414]\n",
      " [-6.080939  ]]\n",
      "[[0.2691347]]\n",
      "[[-0.91595423]\n",
      " [ 0.4012827 ]\n",
      " [-5.954361  ]]\n",
      "[[-2.7294614]]\n",
      "[[-0.75797933]\n",
      " [ 0.6522786 ]\n",
      " [-5.953399  ]]\n",
      "[[-2.8281546]]\n",
      "[[-0.54131496]\n",
      " [ 0.84081995]\n",
      " [-5.76419   ]]\n",
      "[[-0.06515142]]\n",
      "[[-0.30965742]\n",
      " [ 0.95084816]\n",
      " [-5.143348  ]]\n",
      "[[-1.9637228]]\n",
      "[[-0.07851336]\n",
      " [ 0.9969131 ]\n",
      " [-4.7247705 ]]\n",
      "[[2.627855]]\n",
      "[[ 0.1050657]\n",
      " [ 0.9944653]\n",
      " [-3.6770856]]\n",
      "[[-5.9125767]]\n",
      "[[ 0.26366705]\n",
      " [ 0.96461374]\n",
      " [-3.2312367 ]]\n",
      "[[-2.3142016]]\n",
      "[[ 0.39604962]\n",
      " [ 0.9182291 ]\n",
      " [-2.8077765 ]]\n",
      "[[-6.261577]]\n",
      "[[ 0.50395  ]\n",
      " [ 0.8637328]\n",
      " [-2.4191046]]\n",
      "[[3.8401637]]\n",
      "[[ 0.5660704]\n",
      " [ 0.8243569]\n",
      " [-1.4713049]]\n",
      "[[2.451821]]\n",
      "[[ 0.58864605]\n",
      " [ 0.80839086]\n",
      " [-0.5530372 ]]\n",
      "[[-5.285561]]\n",
      "[[ 0.59857434]\n",
      " [ 0.8010673 ]\n",
      " [-0.24674413]]\n",
      "[[2.3548586]]\n",
      "[[0.5720618]\n",
      " [0.8202105]\n",
      " [0.6540563]]\n",
      "[[0.8325744]]\n",
      "[[0.51354605]\n",
      " [0.858062  ]\n",
      " [1.3941004 ]]\n",
      "[[1.6264873]]\n",
      "[[0.4125315]\n",
      " [0.9109433]\n",
      " [2.28162  ]]\n",
      "[[-1.307036]]\n",
      "[[0.2828774]\n",
      " [0.9591561]\n",
      " [2.7687721]]\n",
      "[[-1.9344506]]\n",
      "[[0.1265538 ]\n",
      " [0.99195975]\n",
      " [3.1979716 ]]\n",
      "[[3.7836242]]\n",
      "[[-0.08509992]\n",
      " [ 0.9963724 ]\n",
      " [ 4.2419415 ]]\n",
      "[[0.95927477]]\n",
      "[[-0.33523867]\n",
      " [ 0.94213325]\n",
      " [ 5.133112  ]]\n",
      "[[3.9555109]]\n",
      "[[-0.60426587]\n",
      " [ 0.79678273]\n",
      " [ 6.139712  ]]\n",
      "[[-2.5236473]]\n",
      "[[-0.8252863 ]\n",
      " [ 0.56471455]\n",
      " [ 6.437299  ]]\n",
      "[[-0.6304778]]\n",
      "[[-0.96593237]\n",
      " [ 0.25879472]\n",
      " [ 6.766263  ]]\n",
      "[[1.0706351]]\n",
      "[[-0.9955596 ]\n",
      " [-0.09413384]\n",
      " [ 7.1209545 ]]\n",
      "[[0.9588182]]\n",
      "[[-0.89870787]\n",
      " [-0.43854785]\n",
      " [ 7.194177  ]]\n",
      "[[-5.6337566]]\n",
      "[[-0.7093325]\n",
      " [-0.704874 ]\n",
      " [ 6.5652666]]\n",
      "[[0.1522592]]\n",
      "[[-0.46672007]\n",
      " [-0.8844051 ]\n",
      " [ 6.05945   ]]\n",
      "[[-1.1553501]]\n",
      "[[-0.22255681]\n",
      " [-0.97491974]\n",
      " [ 5.2228436 ]]\n",
      "[[-1.3675019]]\n",
      "[[-0.01010972]\n",
      " [-0.9999489 ]\n",
      " [ 4.2865286 ]]\n",
      "[[0.58057624]]\n",
      "[[ 0.17023976]\n",
      " [-0.98540264]\n",
      " [ 3.6236534 ]]\n",
      "[[3.3603766]]\n",
      "[[ 0.32432985]\n",
      " [-0.9459441 ]\n",
      " [ 3.1846015 ]]\n",
      "[[-0.17715243]]\n",
      "[[ 0.4374236]\n",
      " [-0.8992556]\n",
      " [ 2.4485707]]\n",
      "[[-2.6039338]]\n",
      "[[ 0.502457  ]\n",
      " [-0.86460215]\n",
      " [ 1.474129  ]]\n",
      "[[-0.35062516]]\n",
      "[[ 0.535494  ]\n",
      " [-0.84453905]\n",
      " [ 0.7730835 ]]\n",
      "[[1.395389]]\n",
      "[[ 0.5501484]\n",
      " [-0.8350669]\n",
      " [ 0.3489875]]\n",
      "[[-2.11459]]\n",
      "[[ 0.5258177]\n",
      " [-0.8505973]\n",
      " [-0.5773127]]\n",
      "[[6.918793]]\n",
      "[[ 0.4863549 ]\n",
      " [-0.87376136]\n",
      " [-0.9152608 ]]\n",
      "[[4.4595294]]\n",
      "[[ 0.4299019]\n",
      " [-0.9028756]\n",
      " [-1.2705818]]\n",
      "[[2.2050982]]\n",
      "[[ 0.35414264]\n",
      " [-0.9351914 ]\n",
      " [-1.6477386 ]]\n",
      "[[-0.5109684]]\n",
      "[[ 0.23839062]\n",
      " [-0.97116935]\n",
      " [-2.4257774 ]]\n",
      "[[-0.63072294]]\n",
      "[[ 0.07819056]\n",
      " [-0.9969384 ]\n",
      " [-3.2487628 ]]\n",
      "[[2.6387522]]\n",
      "[[-0.10635155]\n",
      " [-0.9943286 ]\n",
      " [-3.6964667 ]]\n",
      "[[-2.1770492]]\n",
      "[[-0.3369388 ]\n",
      " [-0.94152653]\n",
      " [-4.7422132 ]]\n",
      "[[-2.8590474]]\n",
      "[[-0.59001833]\n",
      " [-0.80738986]\n",
      " [-5.7483582 ]]\n",
      "[[-1.7723837]]\n",
      "[[-0.8203767]\n",
      " [-0.5718234]\n",
      " [-6.619758 ]]\n",
      "[[-2.7854946]]\n",
      "[[-0.9710292 ]\n",
      " [-0.23896073]\n",
      " [-7.348626  ]]\n",
      "[[1.9979652]]\n",
      "[[-0.9927952 ]\n",
      " [ 0.11982349]\n",
      " [-7.228152  ]]\n",
      "[[2.2343848]]\n",
      "[[-0.8951511 ]\n",
      " [ 0.44576284]\n",
      " [-6.8382845 ]]\n",
      "[[1.108135]]\n",
      "[[-0.7116773 ]\n",
      " [ 0.70250654]\n",
      " [-6.3377423 ]]\n",
      "[[0.31366324]]\n",
      "[[-0.48266256]\n",
      " [ 0.8758064 ]\n",
      " [-5.763813  ]]\n",
      "[[1.6576326]]\n",
      "episode finished after200 timesteps\n",
      "[ 0.97824516 -0.20745219 -0.58390855]\n",
      "[[-4.7365537]]\n",
      "[[ 0.9661467 ]\n",
      " [-0.25799334]\n",
      " [-1.0394977 ]]\n",
      "[[1.1678998]]\n",
      "[[ 0.9511567 ]\n",
      " [-0.30870864]\n",
      " [-1.0578077 ]]\n",
      "[[-1.3247037]]\n",
      "[[ 0.92557776]\n",
      " [-0.37855747]\n",
      " [-1.4880447 ]]\n",
      "[[-0.39151698]]\n",
      "[[ 0.8871003 ]\n",
      " [-0.46157676]\n",
      " [-1.8306904 ]]\n",
      "[[1.0237837]]\n",
      "[[ 0.83594877]\n",
      " [-0.54880756]\n",
      " [-2.0233054 ]]\n",
      "[[0.46228123]]\n",
      "[[ 0.7653473]\n",
      " [-0.6436175]\n",
      " [-2.3655689]]\n",
      "[[-3.4938924]]\n",
      "[[ 0.654988 ]\n",
      " [-0.7556393]\n",
      " [-3.148282 ]]\n",
      "[[1.0439312]]\n",
      "[[ 0.51091224]\n",
      " [-0.85963285]\n",
      " [-3.5584219 ]]\n",
      "[[-0.62739867]]\n",
      "[[ 0.3158789]\n",
      " [-0.9487995]\n",
      " [-4.2972565]]\n",
      "[[-3.9016094]]\n",
      "[[ 0.05591082]\n",
      " [-0.9984358 ]\n",
      " [-5.308856  ]]\n",
      "[[0.02332419]]\n",
      "[[-0.24427234]\n",
      " [-0.96970665]\n",
      " [-6.054184  ]]\n",
      "[[1.8820964]]\n",
      "[[-0.54108495]\n",
      " [-0.84096795]\n",
      " [-6.4991493 ]]\n",
      "[[-3.4632583]]\n",
      "[[-0.80945337]\n",
      " [-0.5871842 ]\n",
      " [-7.4298754 ]]\n",
      "[[-1.8659004]]\n",
      "[[-0.97588253]\n",
      " [-0.21829635]\n",
      " [-8.        ]]\n",
      "[[2.965855]]\n",
      "[[-0.9850525 ]\n",
      " [ 0.17225431]\n",
      " [-7.8637223 ]]\n",
      "[[-3.0743]]\n",
      "[[-0.839277  ]\n",
      " [ 0.54370403]\n",
      " [-8.        ]]\n",
      "[[-1.897197]]\n",
      "[[-0.56638414]\n",
      " [ 0.8241414 ]\n",
      " [-7.8768015 ]]\n",
      "[[0.91758084]]\n",
      "[[-0.2435835]\n",
      " [ 0.9698799]\n",
      " [-7.1210585]]\n",
      "[[-3.3118017]]\n",
      "[[ 0.08850757]\n",
      " [ 0.9960755 ]\n",
      " [-6.6936483 ]]\n",
      "[[-3.2846007]]\n",
      "[[ 0.39029622]\n",
      " [ 0.92068934]\n",
      " [-6.2465916 ]]\n",
      "[[2.3462863]]\n",
      "[[ 0.6160804 ]\n",
      " [ 0.78768325]\n",
      " [-5.2560744 ]]\n",
      "[[0.7976481]]\n",
      "[[ 0.7777258 ]\n",
      " [ 0.62860364]\n",
      " [-4.545665  ]]\n",
      "[[-0.5337029]]\n",
      "[[ 0.89064103]\n",
      " [ 0.45470712]\n",
      " [-4.1542673 ]]\n",
      "[[1.1264918]]\n",
      "[[ 0.9582925 ]\n",
      " [ 0.28578934]\n",
      " [-3.644263  ]]\n",
      "[[1.8274331]]\n",
      "[[ 0.9912954 ]\n",
      " [ 0.13165651]\n",
      " [-3.155806  ]]\n",
      "[[0.3336725]]\n",
      "[[ 0.9998324]\n",
      " [-0.0183097]\n",
      " [-3.0070128]]\n",
      "[[-0.3738203]]\n",
      "[[ 0.98521847]\n",
      " [-0.17130268]\n",
      " [-3.076818  ]]\n",
      "[[0.06107339]]\n",
      "[[ 0.9454059]\n",
      " [-0.3258952]\n",
      " [-3.1961339]]\n",
      "[[-1.4490558]]\n",
      "[[ 0.87036455]\n",
      " [-0.4924079 ]\n",
      " [-3.6579134 ]]\n",
      "[[2.5093637]]\n",
      "[[ 0.76405895]\n",
      " [-0.6451465 ]\n",
      " [-3.7272193 ]]\n",
      "[[-3.4776597]]\n",
      "[[ 0.60042095]\n",
      " [-0.7996841 ]\n",
      " [-4.5110793 ]]\n",
      "[[-2.0350955]]\n",
      "[[ 0.3648626]\n",
      " [-0.9310614]\n",
      " [-5.4108424]]\n",
      "[[2.5739775]]\n",
      "[[ 0.08293309]\n",
      " [-0.9965551 ]\n",
      " [-5.8091383 ]]\n",
      "[[-5.615706]]\n",
      "[[-0.25688663]\n",
      " [-0.9664416 ]\n",
      " [-6.8565545 ]]\n",
      "[[-2.4447904]]\n",
      "[[-0.60826194]\n",
      " [-0.7937364 ]\n",
      " [-7.881386  ]]\n",
      "[[-2.3811681]]\n",
      "[[-0.8878739 ]\n",
      " [-0.46008694]\n",
      " [-8.        ]]\n",
      "[[-1.9045757]]\n",
      "[[-0.9989165 ]\n",
      " [-0.04653868]\n",
      " [-8.        ]]\n",
      "[[-0.11495782]]\n",
      "[[-0.9372805 ]\n",
      " [ 0.34857607]\n",
      " [-8.        ]]\n",
      "[[0.6415005]]\n",
      "[[-0.7397021]\n",
      " [ 0.6729345]\n",
      " [-7.642343 ]]\n",
      "[[1.8839957]]\n",
      "[[-0.4705157 ]\n",
      " [ 0.88239163]\n",
      " [-6.855043  ]]\n",
      "[[-0.7245243]]\n",
      "[[-0.1738898]\n",
      " [ 0.9847651]\n",
      " [-6.301928 ]]\n",
      "[[-0.88024575]]\n",
      "[[ 0.10977009]\n",
      " [ 0.993957  ]\n",
      " [-5.695391  ]]\n",
      "[[-0.10641306]]\n",
      "[[ 0.35066923]\n",
      " [ 0.93649936]\n",
      " [-4.965885  ]]\n",
      "[[2.0294676]]\n",
      "[[ 0.5281845]\n",
      " [ 0.8491296]\n",
      " [-3.9635105]]\n",
      "[[-0.7594569]]\n",
      "[[ 0.66574407]\n",
      " [ 0.7461802 ]\n",
      " [-3.4405818 ]]\n",
      "[[2.8243315]]\n",
      "[[ 0.75623393]\n",
      " [ 0.65430135]\n",
      " [-2.5809464 ]]\n",
      "[[-2.3919935]]\n",
      "[[ 0.82884973]\n",
      " [ 0.55947125]\n",
      " [-2.3902202 ]]\n",
      "[[0.8165032]]\n",
      "[[ 0.8769391 ]\n",
      " [ 0.48060152]\n",
      " [-1.848141  ]]\n",
      "[[2.722898]]\n",
      "[[ 0.9039167]\n",
      " [ 0.4277085]\n",
      " [-1.1876895]]\n",
      "[[4.8321033]]\n",
      "[[ 0.91567546]\n",
      " [ 0.4019185 ]\n",
      " [-0.56690794]]\n",
      "[[-2.9809728]]\n",
      "[[ 0.9266716 ]\n",
      " [ 0.3758719 ]\n",
      " [-0.56546885]]\n",
      "[[1.4866475]]\n",
      "[[ 0.9278055 ]\n",
      " [ 0.37306428]\n",
      " [-0.06056756]]\n",
      "[[-3.1682444]]\n",
      "[[ 0.92930466]\n",
      " [ 0.36931401]\n",
      " [-0.08076912]]\n",
      "[[-0.10830563]]\n",
      "[[0.9259437 ]\n",
      " [0.37766165]\n",
      " [0.1799708 ]]\n",
      "[[-0.36659813]]\n",
      "[[0.91804266]\n",
      " [0.39648157]\n",
      " [0.40822756]]\n",
      "[[-2.8513298]]\n",
      "[[0.9098139 ]\n",
      " [0.41501656]\n",
      " [0.40558895]]\n",
      "[[-1.2563474]]\n",
      "[[0.89853305]\n",
      " [0.4389059 ]\n",
      " [0.52839947]]\n",
      "[[-4.8195734]]\n",
      "[[0.8859493 ]\n",
      " [0.46378207]\n",
      " [0.5575791 ]]\n",
      "[[3.7379403]]\n",
      "[[0.85640484]\n",
      " [0.5163049 ]\n",
      " [1.205416  ]]\n",
      "[[-1.9685562]]\n",
      "[[0.82113546]\n",
      " [0.5707333 ]\n",
      " [1.2973615 ]]\n",
      "[[-4.4489694]]\n",
      "[[0.7784086 ]\n",
      " [0.62775797]\n",
      " [1.4254117 ]]\n",
      "[[0.01431394]]\n",
      "[[0.7154078 ]\n",
      " [0.69870716]\n",
      " [1.8983774 ]]\n",
      "[[0.04157715]]\n",
      "[[0.62550235]\n",
      " [0.7802223 ]\n",
      " [2.4286447 ]]\n",
      "[[-0.79643035]]\n",
      "[[0.50644594]\n",
      " [0.8622717 ]\n",
      " [2.894347  ]]\n",
      "[[-2.6341097]]\n",
      "[[0.3606884]\n",
      " [0.9326864]\n",
      " [3.241051 ]]\n",
      "[[-0.9865048]]\n",
      "[[0.17841592]\n",
      " [0.98395514]\n",
      " [3.7925901 ]]\n",
      "[[-0.4432223]]\n",
      "[[-0.04381332]\n",
      " [ 0.9990397 ]\n",
      " [ 4.464073  ]]\n",
      "[[2.7781682]]\n",
      "[[-0.3140867]\n",
      " [ 0.9493943]\n",
      " [ 5.513353 ]]\n",
      "[[2.157265]]\n",
      "[[-0.60180926]\n",
      " [ 0.79863983]\n",
      " [ 6.5253987 ]]\n",
      "[[2.9175236]]\n",
      "[[-0.8505253]\n",
      " [ 0.5259341]\n",
      " [ 7.4243784]]\n",
      "[[-1.3210351]]\n",
      "[[-0.98511076]\n",
      " [ 0.17192073]\n",
      " [ 7.6206737 ]]\n",
      "[[2.2258313]]\n",
      "[[-0.9737343 ]\n",
      " [-0.22768733]\n",
      " [ 8.        ]]\n",
      "[[2.1513667]]\n",
      "[[-0.8043809 ]\n",
      " [-0.59411395]\n",
      " [ 8.        ]]\n",
      "[[0.79886055]]\n",
      "[[-0.523472  ]\n",
      " [-0.85204285]\n",
      " [ 7.6742435 ]]\n",
      "[[-1.2628119]]\n",
      "[[-0.20712069]\n",
      " [-0.9783154 ]\n",
      " [ 6.8457894 ]]\n",
      "[[2.7519717]]\n",
      "[[ 0.11173769]\n",
      " [-0.99373776]\n",
      " [ 6.4120526 ]]\n",
      "[[-0.65184134]]\n",
      "[[ 0.38057694]\n",
      " [-0.92474926]\n",
      " [ 5.568973  ]]\n",
      "[[4.3326273]]\n",
      "[[ 0.60454184]\n",
      " [-0.7965734 ]\n",
      " [ 5.175411  ]]\n",
      "[[4.971242]]\n",
      "[[ 0.77901256]\n",
      " [-0.6270083 ]\n",
      " [ 4.877981  ]]\n",
      "[[1.1845613]]\n",
      "[[ 0.9011261]\n",
      " [-0.4335571]\n",
      " [ 4.585409 ]]\n",
      "[[-2.742229]]\n",
      "[[ 0.9688073]\n",
      " [-0.2478153]\n",
      " [ 3.9602413]]\n",
      "[[3.5076907]]\n",
      "[[ 0.9989095 ]\n",
      " [-0.04668844]\n",
      " [ 4.07438   ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.5990212]]\n",
      "[[0.9860454]\n",
      " [0.1664765]\n",
      " [4.279217 ]]\n",
      "[[-2.662684]]\n",
      "[[0.9314354]\n",
      " [0.3639067]\n",
      " [4.104074 ]]\n",
      "[[-1.8667493]]\n",
      "[[0.8379346]\n",
      " [0.5457706]\n",
      " [4.0969915]]\n",
      "[[-4.6527243]]\n",
      "[[0.70553064]\n",
      " [0.7086794 ]\n",
      " [4.2063193 ]]\n",
      "[[-0.09789586]]\n",
      "[[0.52013946]\n",
      " [0.85408133]\n",
      " [4.7231445 ]]\n",
      "[[6.289461]]\n",
      "[[0.26077873]\n",
      " [0.9653986 ]\n",
      " [5.663706  ]]\n",
      "[[-6.980069]]\n",
      "[[-0.04054768]\n",
      " [ 0.9991776 ]\n",
      " [ 6.0877547 ]]\n",
      "[[2.1899042]]\n",
      "[[-0.38703668]\n",
      " [ 0.9220643 ]\n",
      " [ 7.137138  ]]\n",
      "[[0.44228253]]\n",
      "[[-0.711877 ]\n",
      " [ 0.7023042]\n",
      " [ 7.8950286]]\n",
      "[[1.8140976]]\n",
      "[[-0.9414349 ]\n",
      " [ 0.33719477]\n",
      " [ 8.        ]]\n",
      "[[0.44902456]]\n",
      "[[-0.99740356]\n",
      " [-0.07201456]\n",
      " [ 8.        ]]\n",
      "[[2.0815094]]\n",
      "[[-0.88496554]\n",
      " [-0.46565655]\n",
      " [ 8.        ]]\n",
      "[[0.2290068]]\n",
      "[[-0.64587176]\n",
      " [-0.7634459 ]\n",
      " [ 7.6851087 ]]\n",
      "[[1.9799621]]\n",
      "[[-0.32564014]\n",
      " [-0.9454938 ]\n",
      " [ 7.4095182 ]]\n",
      "[[-1.0297275]]\n",
      "[[-4.3917000e-03]\n",
      " [-9.9999034e-01]\n",
      " [ 6.5459390e+00]]\n",
      "[[2.971837]]\n",
      "[[ 0.29590765]\n",
      " [-0.9552165 ]\n",
      " [ 6.0959463 ]]\n",
      "[[2.9198341]]\n",
      "[[ 0.55168426]\n",
      " [-0.83405304]\n",
      " [ 5.679534  ]]\n",
      "[[3.3122473]]\n",
      "[[ 0.7526528]\n",
      " [-0.6584176]\n",
      " [ 5.3539944]]\n",
      "[[5.837414]]\n",
      "[[ 0.89573914]\n",
      " [-0.44458   ]\n",
      " [ 5.160181  ]]\n",
      "[[1.6895893]]\n",
      "[[ 0.9787143 ]\n",
      " [-0.20522745]\n",
      " [ 5.0801845 ]]\n",
      "[[0.8608157]]\n",
      "[[0.9989388 ]\n",
      " [0.04605693]\n",
      " [5.0553865 ]]\n",
      "[[-2.3842335]]\n",
      "[[0.9595013 ]\n",
      " [0.28170413]\n",
      " [4.7899294 ]]\n",
      "[[1.2284874]]\n",
      "[[0.8552083 ]\n",
      " [0.51828444]\n",
      " [5.1854806 ]]\n",
      "[[1.1085865]]\n",
      "[[0.67349625]\n",
      " [0.73919064]\n",
      " [5.740482  ]]\n",
      "[[2.028242]]\n",
      "[[0.39786154]\n",
      " [0.9174455 ]\n",
      " [6.594875  ]]\n",
      "[[0.21341571]]\n",
      "[[0.04342247]\n",
      " [0.9990568 ]\n",
      " [7.3149714 ]]\n",
      "[[-0.2255503]]\n",
      "[[-0.35048175]\n",
      " [ 0.9365696 ]\n",
      " [ 8.        ]]\n",
      "[[-3.8525205]]\n",
      "[[-0.7020034]\n",
      " [ 0.7121735]\n",
      " [ 8.       ]]\n",
      "[[0.50094426]]\n",
      "[[-0.93514574]\n",
      " [ 0.3542632 ]\n",
      " [ 8.        ]]\n",
      "[[-2.3092666]]\n",
      "[[-0.9993463 ]\n",
      " [-0.03615101]\n",
      " [ 7.9656973 ]]\n",
      "[[-3.0894818]]\n",
      "[[-0.9138669 ]\n",
      " [-0.40601394]\n",
      " [ 7.6385837 ]]\n",
      "[[4.3786354]]\n",
      "[[-0.69685614]\n",
      " [-0.71721095]\n",
      " [ 7.6340733 ]]\n",
      "[[1.3039768]]\n",
      "[[-0.39532018]\n",
      " [-0.9185434 ]\n",
      " [ 7.2917614 ]]\n",
      "[[-3.7065063]]\n",
      "[[-0.09114709]\n",
      " [-0.99583745]\n",
      " [ 6.302854  ]]\n",
      "[[-2.2540574]]\n",
      "[[ 0.17068519]\n",
      " [-0.98532563]\n",
      " [ 5.2559757 ]]\n",
      "[[1.4511924]]\n",
      "[[ 0.39701107]\n",
      " [-0.91781384]\n",
      " [ 4.7346606 ]]\n",
      "[[2.6096177]]\n",
      "[[ 0.585562  ]\n",
      " [-0.81062764]\n",
      " [ 4.3463    ]]\n",
      "[[0.55298114]]\n",
      "[[ 0.72884744]\n",
      " [-0.6846762 ]\n",
      " [ 3.8212767 ]]\n",
      "[[2.957024]]\n",
      "[[ 0.83986014]\n",
      " [-0.5428029 ]\n",
      " [ 3.6077697 ]]\n",
      "[[2.141783]]\n",
      "[[ 0.921552  ]\n",
      " [-0.38825497]\n",
      " [ 3.5006678 ]]\n",
      "[[0.30583167]]\n",
      "[[ 0.9722881 ]\n",
      " [-0.23378606]\n",
      " [ 3.2553515 ]]\n",
      "[[1.7333874]]\n",
      "[[ 0.9976226 ]\n",
      " [-0.06891394]\n",
      " [ 3.3400204 ]]\n",
      "[[-0.3119406]]\n",
      "[[0.99566853]\n",
      " [0.09297436]\n",
      " [3.2415438 ]]\n",
      "[[5.6836348]]\n",
      "[[0.96278477]\n",
      " [0.27026933]\n",
      " [3.6112747 ]]\n",
      "[[0.76289415]]\n",
      "[[0.891526  ]\n",
      " [0.45296958]\n",
      " [3.928411  ]]\n",
      "[[-0.05659571]]\n",
      "[[0.7756348]\n",
      " [0.6311819]\n",
      " [4.2596493]]\n",
      "[[5.82173]]\n",
      "[[0.59403735]\n",
      " [0.80443746]\n",
      " [5.0330358 ]]\n",
      "[[2.1429362]]\n",
      "[[0.33278015]\n",
      " [0.9430044 ]\n",
      " [5.9363637 ]]\n",
      "[[-3.701651]]\n",
      "[[0.0220678 ]\n",
      " [0.99975646]\n",
      " [6.343617  ]]\n",
      "[[-4.4482727]]\n",
      "[[-0.31228986]\n",
      " [ 0.9499869 ]\n",
      " [ 6.793434  ]]\n",
      "[[1.2815176]]\n",
      "[[-0.64613557]\n",
      " [ 0.76322263]\n",
      " [ 7.698152  ]]\n",
      "[[-3.4230947]]\n",
      "[[-0.89167786]\n",
      " [ 0.4526705 ]\n",
      " [ 7.9705687 ]]\n",
      "[[-1.3220452]]\n",
      "[[-0.9979418 ]\n",
      " [ 0.06412583]\n",
      " [ 8.        ]]\n",
      "[[-2.5349526]]\n",
      "[[-0.948213 ]\n",
      " [-0.3176353]\n",
      " [ 7.748094 ]]\n",
      "[[-2.0927033]]\n",
      "[[-0.775223  ]\n",
      " [-0.63168764]\n",
      " [ 7.2098675 ]]\n",
      "[[2.3163435]]\n",
      "[[-0.5100676]\n",
      " [-0.8601343]\n",
      " [ 7.0361013]]\n",
      "[[0.15264943]]\n",
      "[[-0.21292578]\n",
      " [-0.97706836]\n",
      " [ 6.413898  ]]\n",
      "[[-0.24264967]]\n",
      "[[ 0.06761509]\n",
      " [-0.9977115 ]\n",
      " [ 5.644699  ]]\n",
      "[[-3.3600447]]\n",
      "[[ 0.2931194 ]\n",
      " [-0.95607585]\n",
      " [ 4.5964155 ]]\n",
      "[[-1.5905514]]\n",
      "[[ 0.46135974]\n",
      " [-0.8872132 ]\n",
      " [ 3.6407762 ]]\n",
      "[[-1.8989228]]\n",
      "[[ 0.5761851]\n",
      " [-0.8173192]\n",
      " [ 2.690528 ]]\n",
      "[[3.9645317]]\n",
      "[[ 0.66905004]\n",
      " [-0.74321735]\n",
      " [ 2.3775387 ]]\n",
      "[[-0.7111492]]\n",
      "[[ 0.7301915]\n",
      " [-0.6832425]\n",
      " [ 1.7134535]]\n",
      "[[1.8559289]]\n",
      "[[ 0.77868867]\n",
      " [-0.6274105 ]\n",
      " [ 1.4794111 ]]\n",
      "[[-3.3336482]]\n",
      "[[ 0.8004319]\n",
      " [-0.5994237]\n",
      " [ 0.7088534]]\n",
      "[[3.3041213]]\n",
      "[[ 0.8168794]\n",
      " [-0.5768085]\n",
      " [ 0.5592859]]\n",
      "[[-0.37188715]]\n",
      "[[ 0.81891894]\n",
      " [-0.57390916]\n",
      " [ 0.07089663]]\n",
      "[[-1.8498937]]\n",
      "[[ 0.8002272 ]\n",
      " [-0.59969693]\n",
      " [-0.63701916]]\n",
      "[[-2.766953]]\n",
      "[[ 0.7567547]\n",
      " [-0.6536989]\n",
      " [-1.3867917]]\n",
      "[[0.66514385]]\n",
      "[[ 0.6957546]\n",
      " [-0.7182796]\n",
      " [-1.7772942]]\n",
      "[[-2.6571615]]\n",
      "[[ 0.59612787]\n",
      " [-0.8028895 ]\n",
      " [-2.6160038 ]]\n",
      "[[-1.1070105]]\n",
      "[[ 0.45240325]\n",
      " [-0.8918135 ]\n",
      " [-3.3842223 ]]\n",
      "[[2.5747898]]\n",
      "[[ 0.27808875]\n",
      " [-0.9605554 ]\n",
      " [-3.7530823 ]]\n",
      "[[0.6569302]]\n",
      "[[ 0.06301393]\n",
      " [-0.99801266]\n",
      " [-4.374959  ]]\n",
      "[[0.80205524]]\n",
      "[[-0.18601285]\n",
      " [-0.9825473 ]\n",
      " [-5.00316   ]]\n",
      "[[-0.07962131]]\n",
      "[[-0.4570744 ]\n",
      " [-0.88942844]\n",
      " [-5.7520137 ]]\n",
      "[[0.5025907]]\n",
      "[[-0.7116806]\n",
      " [-0.7025032]\n",
      " [-6.3436966]]\n",
      "[[-3.461076]]\n",
      "[[-0.91293406]\n",
      " [-0.4081071 ]\n",
      " [-7.170574  ]]\n",
      "[[1.531753]]\n",
      "[[-0.99831647]\n",
      " [-0.05800235]\n",
      " [-7.246892  ]]\n",
      "[[0.08368039]]\n",
      "[[-0.9535891]\n",
      " [ 0.3011111]\n",
      " [-7.277842 ]]\n",
      "[[0.1184742]]\n",
      "[[-0.7914799 ]\n",
      " [ 0.61119527]\n",
      " [-7.034238  ]]\n",
      "[[1.1810867]]\n",
      "[[-0.55909395]\n",
      " [ 0.8291043 ]\n",
      " [-6.398679  ]]\n",
      "[[-1.4377247]]\n",
      "[[-0.28946435]\n",
      " [ 0.9571888 ]\n",
      " [-5.9925094 ]]\n",
      "[[0.77093697]]\n",
      "[[-0.03571071]\n",
      " [ 0.9993622 ]\n",
      " [-5.158977  ]]\n",
      "[[1.4066981]]\n",
      "[[ 0.17332426]\n",
      " [ 0.98486483]\n",
      " [-4.1984506 ]]\n",
      "[[-1.6789281]]\n",
      "[[ 0.35207412]\n",
      " [ 0.93597215]\n",
      " [-3.7116413 ]]\n",
      "[[-1.9758638]]\n",
      "[[ 0.50128955]\n",
      " [ 0.8652796 ]\n",
      " [-3.3060417 ]]\n",
      "[[-1.6931214]]\n",
      "[[ 0.62148833]\n",
      " [ 0.7834234 ]\n",
      " [-2.9110503 ]]\n",
      "[[-1.461132]]\n",
      "[[ 0.7158031 ]\n",
      " [ 0.69830215]\n",
      " [-2.5426526 ]]\n",
      "[[0.39615855]]\n",
      "[[ 0.7806772 ]\n",
      " [ 0.62493443]\n",
      " [-1.9595022 ]]\n",
      "[[4.492877]]\n",
      "[[ 0.81648064]\n",
      " [ 0.5773728 ]\n",
      " [-1.1908011 ]]\n",
      "[[-1.1078638]]\n",
      "[[ 0.8422732 ]\n",
      " [ 0.53905094]\n",
      " [-0.92395115]]\n",
      "[[4.926309]]\n",
      "[[ 0.8481427 ]\n",
      " [ 0.52976793]\n",
      " [-0.21966273]]\n",
      "[[-1.1550885]]\n",
      "[[0.84802616]\n",
      " [0.5299543 ]\n",
      " [0.00439979]]\n",
      "[[3.1839411]]\n",
      "[[0.82891   ]\n",
      " [0.55938196]\n",
      " [0.7018658 ]]\n",
      "[[1.3623292]]\n",
      "[[0.7900367 ]\n",
      " [0.61305964]\n",
      " [1.3257518 ]]\n",
      "[[-1.7388717]]\n",
      "[[0.7410501 ]\n",
      " [0.67144966]\n",
      " [1.5247157 ]]\n",
      "[[0.26682973]]\n",
      "[[0.6677757 ]\n",
      " [0.74436253]\n",
      " [2.0683274 ]]\n",
      "[[2.0454018]]\n",
      "[[0.5521049]\n",
      " [0.8337746]\n",
      " [2.9265993]]\n",
      "[[-2.53336]]\n",
      "[[0.40985036]\n",
      " [0.91215277]\n",
      " [3.2519302 ]]\n",
      "[[3.7642684]]\n",
      "[[0.20893714]\n",
      " [0.97792906]\n",
      " [4.236045  ]]\n",
      "[[0.11070588]]\n",
      "[[-0.03880704]\n",
      " [ 0.9992467 ]\n",
      " [ 4.986098  ]]\n",
      "[[5.5910897]]\n",
      "[[-0.33404672]\n",
      " [ 0.9425565 ]\n",
      " [ 6.035533  ]]\n",
      "[[-4.9313006]]\n",
      "[[-0.6152604 ]\n",
      " [ 0.78832394]\n",
      " [ 6.44245   ]]\n",
      "[[5.0416427]]\n",
      "[[-0.8569905 ]\n",
      " [ 0.51533216]\n",
      " [ 7.333693  ]]\n",
      "[[3.394368]]\n",
      "[[-0.99016213]\n",
      " [ 0.13992493]\n",
      " [ 8.        ]]\n",
      "[[-2.1441422]]\n",
      "[[-0.96894664]\n",
      " [-0.24727   ]\n",
      " [ 7.8049436 ]]\n",
      "[[0.5370786]]\n",
      "[[-0.8051519 ]\n",
      " [-0.59306866]\n",
      " [ 7.7000527 ]]\n",
      "[[3.7586524]]\n",
      "[[-0.52963376]\n",
      " [-0.8482264 ]\n",
      " [ 7.555251  ]]\n",
      "[[0.65042734]]\n",
      "[[-0.20585439]\n",
      " [-0.9785826 ]\n",
      " [ 7.0166454 ]]\n",
      "[[3.1221576]]\n",
      "[[ 0.1214973 ]\n",
      " [-0.99259174]\n",
      " [ 6.5827084 ]]\n",
      "[[0.02097768]]\n",
      "[[ 0.40215433]\n",
      " [-0.91557187]\n",
      " [ 5.841411  ]]\n",
      "[[0.97033143]]\n",
      "[[ 0.62792355]\n",
      " [-0.778275  ]\n",
      " [ 5.300282  ]]\n",
      "[[2.6725464]]\n",
      "[[ 0.80144715]\n",
      " [-0.59806556]\n",
      " [ 5.016576  ]]\n",
      "[[2.8003035]]\n",
      "[[ 0.92196053]\n",
      " [-0.3872839 ]\n",
      " [ 4.8680267 ]]\n",
      "[[0.11478795]]\n",
      "[[ 0.98593044]\n",
      " [-0.16715617]\n",
      " [ 4.5947824 ]]\n",
      "[[4.4277573]]\n",
      "[[0.997514  ]\n",
      " [0.07046802]\n",
      " [4.7694154 ]]\n",
      "[[3.0258946]]\n",
      "episode finished after200 timesteps\n",
      "[ 0.24562747 -0.9693643   0.55923913]\n",
      "[[4.5498323]]\n",
      "[[ 0.25203034]\n",
      " [-0.9677193 ]\n",
      " [ 0.13221592]]\n",
      "[[2.9475899]]\n",
      "[[ 0.23779881]\n",
      " [-0.97131443]\n",
      " [-0.2935736 ]]\n",
      "[[1.4078302]]\n",
      "[[ 0.19823295]\n",
      " [-0.98015493]\n",
      " [-0.81088483]]\n",
      "[[2.6594367]]\n",
      "[[ 0.13682413]\n",
      " [-0.99059534]\n",
      " [-1.246001  ]]\n",
      "[[-3.267322]]\n",
      "[[ 0.02280534]\n",
      " [-0.99973994]\n",
      " [-2.2889476 ]]\n",
      "[[-2.5068812]]\n",
      "[[-0.14363177]\n",
      " [-0.9896312 ]\n",
      " [-3.3387527 ]]\n",
      "[[-3.4122136]]\n",
      "[[-0.3552478]\n",
      " [-0.9347722]\n",
      " [-4.380976 ]]\n",
      "[[-1.9411986]]\n",
      "[[-0.59063125]\n",
      " [-0.8069416 ]\n",
      " [-5.373235  ]]\n",
      "[[1.0604863]]\n",
      "[[-0.7973004]\n",
      " [-0.6035827]\n",
      " [-5.8193684]]\n",
      "[[1.1715834]]\n",
      "[[-0.94169235]\n",
      " [-0.33647513]\n",
      " [-6.096318  ]]\n",
      "[[1.6108701]]\n",
      "[[-0.9992849 ]\n",
      " [-0.03781005]\n",
      " [-6.1070437 ]]\n",
      "[[3.3253143]]\n",
      "[[-0.9679274 ]\n",
      " [ 0.25123012]\n",
      " [-5.8354015 ]]\n",
      "[[-0.43902194]]\n",
      "[[-0.8579181]\n",
      " [ 0.5137865]\n",
      " [-5.7128325]]\n",
      "[[-3.5233872]]\n",
      "[[-0.68151367]\n",
      " [ 0.7318054 ]\n",
      " [-5.6274924 ]]\n",
      "[[3.6323614]]\n",
      "[[-0.48896003]\n",
      " [ 0.87230617]\n",
      " [-4.7786384 ]]\n",
      "[[-1.3386937]]\n",
      "[[-0.29039225]\n",
      " [ 0.9569077 ]\n",
      " [-4.325213  ]]\n",
      "[[2.8316875]]\n",
      "[[-0.12890041]\n",
      " [ 0.99165756]\n",
      " [-3.3075323 ]]\n",
      "[[-1.692317]]\n",
      "[[ 0.0116217 ]\n",
      " [ 0.99993247]\n",
      " [-2.8176367 ]]\n",
      "[[-0.3387671]]\n",
      "[[ 0.11727653]\n",
      " [ 0.9930993 ]\n",
      " [-2.1185024 ]]\n",
      "[[1.9441425]]\n",
      "[[ 0.17080829]\n",
      " [ 0.9853043 ]\n",
      " [-1.0820564 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.9988835]]\n",
      "[[ 0.1950371 ]\n",
      " [ 0.98079586]\n",
      " [-0.49291068]]\n",
      "[[3.3592691]]\n",
      "[[0.16835524]\n",
      " [0.9857264 ]\n",
      " [0.54268616]]\n",
      "[[-1.6375474]]\n",
      "[[0.11707433]\n",
      " [0.9931232 ]\n",
      " [1.0363489 ]]\n",
      "[[-3.0092392]]\n",
      "[[0.04327044]\n",
      " [0.9990634 ]\n",
      " [1.4811914 ]]\n",
      "[[0.84271955]]\n",
      "[[-0.07449204]\n",
      " [ 0.9972216 ]\n",
      " [ 2.3568969 ]]\n",
      "[[-0.45502493]]\n",
      "[[-0.22446005]\n",
      " [ 0.9744833 ]\n",
      " [ 3.0365593 ]]\n",
      "[[1.7704954]]\n",
      "[[-0.41508713]\n",
      " [ 0.90978163]\n",
      " [ 4.032996  ]]\n",
      "[[-0.14480951]]\n",
      "[[-0.61526275]\n",
      " [ 0.7883221 ]\n",
      " [ 4.693611  ]]\n",
      "[[4.0174627]]\n",
      "[[-0.80871356]\n",
      " [ 0.58820266]\n",
      " [ 5.5848527 ]]\n",
      "[[-1.811938]]\n",
      "[[-0.94237924]\n",
      " [ 0.33454645]\n",
      " [ 5.754214  ]]\n",
      "[[1.2306463]]\n",
      "[[-0.99949956]\n",
      " [ 0.03163272]\n",
      " [ 6.1897206 ]]\n",
      "[[-2.1306896]]\n",
      "[[-0.965345  ]\n",
      " [-0.26097703]\n",
      " [ 5.913445  ]]\n",
      "[[-1.9015392]]\n",
      "[[-0.85993284]\n",
      " [-0.5104072 ]\n",
      " [ 5.4324813 ]]\n",
      "[[-0.05466375]]\n",
      "[[-0.7054546 ]\n",
      " [-0.70875514]\n",
      " [ 5.0414762 ]]\n",
      "[[1.9552903]]\n",
      "[[-0.5166247 ]\n",
      " [-0.85621196]\n",
      " [ 4.8032036 ]]\n",
      "[[4.6231112]]\n",
      "[[-0.3144259 ]\n",
      " [-0.94928205]\n",
      " [ 4.4610443 ]]\n",
      "[[-2.425771]]\n",
      "[[-0.14686453]\n",
      " [-0.9891566 ]\n",
      " [ 3.4490829 ]]\n",
      "[[-0.29592496]]\n",
      "[[-0.01425592]\n",
      " [-0.9998984 ]\n",
      " [ 2.6628265 ]]\n",
      "[[-0.6132583]]\n",
      "[[ 0.07671389]\n",
      " [-0.99705315]\n",
      " [ 1.820914  ]]\n",
      "[[-0.4298615]]\n",
      "[[ 0.12687863]\n",
      " [-0.99191827]\n",
      " [ 1.0086448 ]]\n",
      "[[2.553439]]\n",
      "[[ 0.15483147]\n",
      " [-0.9879409 ]\n",
      " [ 0.5647061 ]]\n",
      "[[0.02780999]]\n",
      "[[ 0.14632566]\n",
      " [-0.9892365 ]\n",
      " [-0.17207807]]\n",
      "[[3.0235648]]\n",
      "[[ 0.1158916 ]\n",
      " [-0.9932619 ]\n",
      " [-0.61400545]]\n",
      "[[0.86862636]]\n",
      "[[ 0.05469246]\n",
      " [-0.99850327]\n",
      " [-1.228658  ]]\n",
      "[[1.2217262]]\n",
      "[[-0.03498691]\n",
      " [-0.99938774]\n",
      " [-1.7942765 ]]\n",
      "[[2.0729141]]\n",
      "[[-0.14665405]\n",
      " [-0.98918784]\n",
      " [-2.2438173 ]]\n",
      "[[1.4728144]]\n",
      "[[-0.28156447]\n",
      " [-0.95954233]\n",
      " [-2.764786  ]]\n",
      "[[-3.8768487]]\n",
      "[[-0.45702383]\n",
      " [-0.8894544 ]\n",
      " [-3.784443  ]]\n",
      "[[0.00499134]]\n",
      "[[-0.6420624 ]\n",
      " [-0.76665235]\n",
      " [-4.450785  ]]\n",
      "[[-5.490465]]\n",
      "[[-0.82117915]\n",
      " [-0.5706705 ]\n",
      " [-5.3257747 ]]\n",
      "[[4.871964]]\n",
      "[[-0.94453084]\n",
      " [-0.32842278]\n",
      " [-5.453778  ]]\n",
      "[[3.9158285]]\n",
      "[[-0.9979123 ]\n",
      " [-0.06458353]\n",
      " [-5.400095  ]]\n",
      "[[-1.6856066]]\n",
      "[[-0.9758013 ]\n",
      " [ 0.21865922]\n",
      " [-5.7013736 ]]\n",
      "[[-2.230012]]\n",
      "[[-0.8716149 ]\n",
      " [ 0.49019125]\n",
      " [-5.8373795 ]]\n",
      "[[0.6135721]]\n",
      "[[-0.7100733]\n",
      " [ 0.7041278]\n",
      " [-5.3777003]]\n",
      "[[-7.5377874]]\n",
      "[[-0.5073632]\n",
      " [ 0.8617323]\n",
      " [-5.1496043]]\n",
      "[[-2.482221]]\n",
      "[[-0.28782687]\n",
      " [ 0.9576825 ]\n",
      " [-4.803305  ]]\n",
      "[[-2.4928236]]\n",
      "[[-0.07264075]\n",
      " [ 0.99735814]\n",
      " [-4.385043  ]]\n",
      "[[-1.0081735]]\n",
      "[[ 0.11644305]\n",
      " [ 0.9931974 ]\n",
      " [-3.7882504 ]]\n",
      "[[2.2466047]]\n",
      "[[ 0.2511569]\n",
      " [ 0.9679464]\n",
      " [-2.7433524]]\n",
      "[[2.5343888]]\n",
      "[[ 0.33324674]\n",
      " [ 0.9428397 ]\n",
      " [-1.7173926 ]]\n",
      "[[-4.177998]]\n",
      "[[ 0.39425606]\n",
      " [ 0.9190006 ]\n",
      " [-1.3102628 ]]\n",
      "[[2.652291]]\n",
      "[[ 0.40895534]\n",
      " [ 0.9125544 ]\n",
      " [-0.3210122 ]]\n",
      "[[-0.6286343]]\n",
      "[[0.3966399 ]\n",
      " [0.9179743 ]\n",
      " [0.26910853]]\n",
      "[[1.0622343]]\n",
      "[[0.3447828]\n",
      " [0.9386825]\n",
      " [1.1169245]]\n",
      "[[-1.2291903]]\n",
      "[[0.26690423]\n",
      " [0.96372306]\n",
      " [1.6365578 ]]\n",
      "[[-2.798068]]\n",
      "[[0.16643344]\n",
      " [0.9860527 ]\n",
      " [2.05935   ]]\n",
      "[[-4.291728]]\n",
      "[[0.04225427]\n",
      " [0.9991069 ]\n",
      " [2.4988894 ]]\n",
      "[[-3.0532956]]\n",
      "[[-0.10495038]\n",
      " [ 0.99447745]\n",
      " [ 2.9482195 ]]\n",
      "[[-0.2500054]]\n",
      "[[-0.2840092 ]\n",
      " [ 0.95882154]\n",
      " [ 3.6565769 ]]\n",
      "[[2.1955824]]\n",
      "[[-0.49840465]\n",
      " [ 0.86694455]\n",
      " [ 4.675693  ]]\n",
      "[[-1.692957]]\n",
      "[[-0.69997007]\n",
      " [ 0.7141722 ]\n",
      " [ 5.071958  ]]\n",
      "[[-2.1099098]]\n",
      "[[-0.86277604]\n",
      " [ 0.50558627]\n",
      " [ 5.307587  ]]\n",
      "[[-0.73896503]]\n",
      "[[-0.9685988 ]\n",
      " [ 0.24862911]\n",
      " [ 5.575932  ]]\n",
      "[[1.3862109]]\n",
      "[[-0.99888384]\n",
      " [-0.04723451]\n",
      " [ 5.9703355 ]]\n",
      "[[-5.037971]]\n",
      "[[-0.9463667]\n",
      " [-0.3230945]\n",
      " [ 5.6349096]]\n",
      "[[-2.6220393]]\n",
      "[[-0.8344695]\n",
      " [-0.5510541]\n",
      " [ 5.092589 ]]\n",
      "[[0.6608098]]\n",
      "[[-0.68035614]\n",
      " [-0.7328816 ]\n",
      " [ 4.7784195 ]]\n",
      "[[-3.1746016]]\n",
      "[[-0.52423  ]\n",
      " [-0.8515767]\n",
      " [ 3.9287581]]\n",
      "[[-6.386491]]\n",
      "[[-0.39154205]\n",
      " [-0.92016023]\n",
      " [ 2.9900756 ]]\n",
      "[[-1.5048914]]\n",
      "[[-0.29417834]\n",
      " [-0.9557505 ]\n",
      " [ 2.0742216 ]]\n",
      "[[-2.4343235]]\n",
      "[[-0.24325992]\n",
      " [-0.96996117]\n",
      " [ 1.0574087 ]]\n",
      "[[-0.2815554]]\n",
      "[[-0.22928213]\n",
      " [-0.97336   ]\n",
      " [ 0.28770447]]\n",
      "[[-0.08863184]]\n",
      "[[-0.2513944 ]\n",
      " [-0.9678847 ]\n",
      " [-0.45561033]]\n",
      "[[-1.908288]]\n",
      "[[-0.3216854]\n",
      " [-0.9468466]\n",
      " [-1.4677672]]\n",
      "[[1.2136949]]\n",
      "[[-0.41441628]\n",
      " [-0.9100874 ]\n",
      " [-1.995848  ]]\n",
      "[[1.7546532]]\n",
      "[[-0.52103406]\n",
      " [-0.8535359 ]\n",
      " [-2.4152155 ]]\n",
      "[[-4.1497717]]\n",
      "[[-0.6562443]\n",
      " [-0.7545485]\n",
      " [-3.3553674]]\n",
      "[[-2.5472834]]\n",
      "[[-0.7997594 ]\n",
      " [-0.60032064]\n",
      " [-4.2212787 ]]\n",
      "[[-1.8159704]]\n",
      "[[-0.92233866]\n",
      " [-0.3863825 ]\n",
      " [-4.943915  ]]\n",
      "[[0.0530972]]\n",
      "[[-0.9908448]\n",
      " [-0.135006 ]\n",
      " [-5.225737 ]]\n",
      "[[2.5514731]]\n",
      "[[-0.9932876 ]\n",
      " [ 0.11567067]\n",
      " [-5.026992  ]]\n",
      "[[0.8499718]]\n",
      "[[-0.9371006 ]\n",
      " [ 0.34905943]\n",
      " [-4.812743  ]]\n",
      "[[-3.3306594]]\n",
      "[[-0.82583517]\n",
      " [ 0.5639116 ]\n",
      " [-4.850949  ]]\n",
      "[[-2.4817486]]\n",
      "[[-0.6707954]\n",
      " [ 0.7416425]\n",
      " [-4.728015 ]]\n",
      "[[-0.3807722]]\n",
      "[[-0.5002051 ]\n",
      " [ 0.86590695]\n",
      " [-4.228899  ]]\n",
      "[[-0.6797216]]\n",
      "[[-0.33326468]\n",
      " [ 0.9428333 ]\n",
      " [-3.681427  ]]\n",
      "[[0.82582736]]\n",
      "[[-0.19596626]\n",
      " [ 0.9806106 ]\n",
      " [-2.8504279 ]]\n",
      "[[3.5222023]]\n",
      "[[-0.10629324]\n",
      " [ 0.9943348 ]\n",
      " [-1.8149699 ]]\n",
      "[[-1.113576]]\n",
      "[[-0.04466667]\n",
      " [ 0.9990019 ]\n",
      " [-1.2362552 ]]\n",
      "[[-2.9325452]]\n",
      "[[-0.00533148]\n",
      " [ 0.9999858 ]\n",
      " [-0.7870037 ]]\n",
      "[[3.927479]]\n",
      "[[-0.01847971]\n",
      " [ 0.99982923]\n",
      " [ 0.26298565]]\n",
      "[[2.6267388]]\n",
      "[[-0.08402441]\n",
      " [ 0.9964637 ]\n",
      " [ 1.3128576 ]]\n",
      "[[2.3691874]]\n",
      "[[-0.20076045]\n",
      " [ 0.97964036]\n",
      " [ 2.3602057 ]]\n",
      "[[-5.6724725]]\n",
      "[[-0.33525962]\n",
      " [ 0.9421258 ]\n",
      " [ 2.794936  ]]\n",
      "[[-1.544238]]\n",
      "[[-0.48413593]\n",
      " [ 0.8749928 ]\n",
      " [ 3.2698946 ]]\n",
      "[[-0.48795885]]\n",
      "[[-0.6427042]\n",
      " [ 0.7661144]\n",
      " [ 3.8529453]]\n",
      "[[-3.0602913]]\n",
      "[[-0.786054 ]\n",
      " [ 0.6181578]\n",
      " [ 4.127531 ]]\n",
      "[[3.1999674]]\n",
      "[[-0.9123373 ]\n",
      " [ 0.40943944]\n",
      " [ 4.8911495 ]]\n",
      "[[-2.9049911]]\n",
      "[[-0.984389 ]\n",
      " [ 0.1760065]\n",
      " [ 4.898229 ]]\n",
      "[[4.540774]]\n",
      "[[-0.9959901 ]\n",
      " [-0.08946378]\n",
      " [ 5.330234  ]]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make(\"Pendulum-v0\")\n",
    "for i_episode in range(1000):\n",
    "    observation = env.reset()\n",
    "    for t in range(10000):\n",
    "        env.render()\n",
    "        print(observation)\n",
    "        action=alg.compute_action(observation.reshape(1,3))\n",
    "        print(action)\n",
    "        observation, reward, done, info=env.step(action)\n",
    "        if done:\n",
    "            print(\"episode finished after{} timesteps\".format(t+1))\n",
    "            break\n",
    "env.close\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(self, mode='human'):\n",
    "        if self.viewer is None:\n",
    "            from gym.envs.classic_control import rendering\n",
    "            self.viewer = rendering.Viewer(500, 500)\n",
    "            self.viewer.set_bounds(-2.2, 2.2, -2.2, 2.2)\n",
    "            rod = rendering.make_capsule(1, .2)\n",
    "            rod.set_color(.8, .3, .3)\n",
    "            self.pole_transform = rendering.Transform()\n",
    "            rod.add_attr(self.pole_transform)\n",
    "            self.viewer.add_geom(rod)\n",
    "            axle = rendering.make_circle(.05)\n",
    "            axle.set_color(0, 0, 0)\n",
    "            self.viewer.add_geom(axle)\n",
    "            fname = path.join(path.dirname(__file__), \"assets/clockwise.png\")\n",
    "            self.img = rendering.Image(fname, 1., 1.)\n",
    "            self.imgtrans = rendering.Transform()\n",
    "            self.img.add_attr(self.imgtrans)\n",
    "\n",
    "        self.viewer.add_onetime(self.img)\n",
    "        self.pole_transform.set_rotation(self.state[0] + np.pi / 2)\n",
    "        if self.last_u:\n",
    "            self.imgtrans.scale = (-self.last_u / 2, np.abs(self.last_u) / 2)\n",
    "\n",
    "        return self.viewer.render(return_rgb_array=mode == 'rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'shapes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-454e6a96b2b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'trainig iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplot_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_results\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-454e6a96b2b5>\u001b[0m in \u001b[0;36mplot_results\u001b[1;34m(all_results, labels)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mcolors\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mall_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         plt.plot(np.arange(result.shapes[1]), np.mean(result,0),\n\u001b[0m\u001b[0;32m     15\u001b[0m                 color=colors(i), linewidth=2, label=label)\n\u001b[0;32m     16\u001b[0m         plt.fill_between(np.arange(len(result[0])),\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'shapes'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x648 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# collect saved results\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "r1 = np.genfromtxt(\"InvertedPendulum_results.csv\", delimiter=\",\")\n",
    "all_results = [r1]\n",
    "labels = [\"REINFORCE\"]\n",
    "\n",
    "##############################################################\n",
    "# Plotting Policy Gradient results below\n",
    "##############################################################\n",
    "def plot_results(all_results,labels):\n",
    "    colors= plt.figure(figsize=(16,9))\n",
    "    for i,(label,result) in enumerate(zip(labels,all_results)):\n",
    "        plt.plot(np.arange(result.shapes[1]), np.mean(result,0),\n",
    "                color=colors(i), linewidth=2, label=label)\n",
    "        plt.fill_between(np.arange(len(result[0])),\n",
    "                        np.mean(result,0)-np.std(result,0),\n",
    "                        np.mean(result,0)+np.std(result,0),\n",
    "                        alpha=0.25, color=colors(i))\n",
    "    plt.ylabel('cumulative return')\n",
    "    plt.xlabel('trainig iteration')\n",
    "%matplotlib inline\n",
    "fig=plot_results(all_results,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
